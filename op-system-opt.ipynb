{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd6ea697",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-22T23:33:24.654642Z",
     "iopub.status.busy": "2026-01-22T23:33:24.654311Z",
     "iopub.status.idle": "2026-01-22T23:34:10.060286Z",
     "shell.execute_reply": "2026-01-22T23:34:10.059393Z"
    },
    "papermill": {
     "duration": 45.415551,
     "end_time": "2026-01-22T23:34:10.062150",
     "exception": false,
     "start_time": "2026-01-22T23:33:24.646599",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ SYSTEM ONLINE: TITAN OS OPTIMIZER | DEVICE: cuda\n",
      "==================================================================================\n",
      "üåå INITIATING GRAND UNIFIED DATA INGESTION (REAL PHYSICS, EXPANDED)\n",
      "==================================================================================\n",
      ">> [SOURCE 1] Fetching OS Kernel Data (Delve: 'cpu_act', ID 197)...\n",
      "   ‚úì OS Data Secured: (8192, 22) - (System Calls, I/O, Interrupts)\n",
      ">> [SOURCE 2] Fetching CPU Performance Regression Data (ID 533)...\n",
      "   ‚úì CPU Perf Data Secured: (559, 5)\n",
      ">> [SOURCE 3] Fetching Exotic Hardware Data (Superconduct, ID 44148)...\n",
      "   ‚úì Hardware Data Secured: (21263, 80) - (81 features + critical_temp)\n",
      "\n",
      ">> [FUSION] Merging OS + CPUPerf + Hardware into 'Penrose Ring' Matrix...\n",
      "‚úì FUSION COMPLETE. Matrix: (8192, 51)\n",
      "\n",
      "[PHASE 1] VALIDATION SCAN\n",
      "   [TVF] Learning Baseline Structure (Manifold & Anomalies)...\n",
      "   Module Status               Reason\n",
      "0  Global  GREEN  All Systems Nominal\n",
      "\n",
      "[PHASE 2] DISCOVERING INFLUENTIAL PARAMETERS\n",
      "üîç UDE ONLINE. Target: 'usr'\n",
      "\n",
      ">> [UDE] SCANNING NON-LINEAR PHYSICS...\n",
      "   Baseline R¬≤: 0.9983\n",
      "   Top Drivers: ['freeswap', 'vflt', 'runqsz', 'scall', 'swrite', 'ppgin', 'exec', 'pgin', 'pflt', 'pgout', 'sread', 'freemem', 'wchar', 'rchar', 'ppgout', 'pgfree', 'lread', 'fork', 'pgscan', 'lwrite']\n",
      "\n",
      ">> [UDE] PURGING REDUNDANT DIMENSIONS...\n",
      "   ‚öîÔ∏è Killed 'pgin' (Redundant with Survivors, R¬≤=0.92)\n",
      "   ‚öîÔ∏è Killed 'pflt' (Redundant with Survivors, R¬≤=0.93)\n",
      "   ‚öîÔ∏è Killed 'ppgout' (Redundant with Survivors, R¬≤=0.91)\n",
      "   ‚öîÔ∏è Killed 'fork' (Redundant with Survivors, R¬≤=0.96)\n",
      "   ‚öîÔ∏è Killed 'pgscan' (Redundant with Survivors, R¬≤=0.93)\n",
      "   Unique Control Knobs: ['freeswap', 'vflt', 'runqsz', 'scall', 'swrite', 'ppgin', 'exec', 'pgout', 'sread', 'freemem', 'wchar', 'rchar', 'pgfree', 'lread', 'lwrite']\n",
      "\n",
      "[PHASE 3] DECODING PHYSICS (Attribution)\n",
      "\n",
      "‚öñÔ∏è [UAV] TRAINING DIFFERENTIABLE SURROGATE...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2136fec42d804dc7bd3ba6a000ba6e40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "   Training Surrogate:   0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   [UAV] Calculating Gradient Flows (Sensitivity)...\n",
      "\n",
      "üèÜ PARAMETER IMPACT (Sensitivity):\n",
      "runqsz      0.001585\n",
      "vflt        0.000907\n",
      "freeswap    0.000572\n",
      "rchar       0.000267\n",
      "lread       0.000229\n",
      "wchar       0.000162\n",
      "pgout       0.000156\n",
      "sread       0.000132\n",
      "exec        0.000100\n",
      "lwrite      0.000030\n",
      "swrite      0.000020\n",
      "scall      -0.000025\n",
      "pgfree     -0.000075\n",
      "ppgin      -0.000088\n",
      "freemem    -0.001517\n",
      "dtype: float32\n",
      "\n",
      "[PHASE 4] SIMULATING INTERVENTIONS\n",
      "\n",
      "‚öôÔ∏è [UIF] FITTING CAUSAL MECHANISMS...\n",
      ">> Simulating 'Kernel Bypass' (scall = 0.1)...\n",
      "   Predicted User CPU (normalized): 0.861 (¬±0.175)\n",
      "\n",
      "[PHASE 5] PENROSE RING OPTIMIZATION (Regularized)\n",
      "üß¨ [UOF] RUNNING GENETIC EVOLUTION...\n",
      "\n",
      "[PHASE 6] EXPORTING DEVELOPER BLUEPRINT\n",
      "\n",
      "==================================================================================\n",
      "üèÅ FINAL SYSTEM BLUEPRINT (Original Units)\n",
      "==================================================================================\n",
      "üåü MAX ACHIEVABLE USER CPU (normalized surrogate): 40.40%\n",
      "\n",
      "üîß OPTIMAL CONTROL SURFACE (Top by Sensitivity):\n",
      "Parameter  Original_Min  Original_Max  Recommended_Value Sensitivity_Sign  Sensitivity_Magnitude\n",
      "   runqsz           1.0       2823.00       1.804045e+02         Positive               0.001585\n",
      "  freemem          55.0      12027.00       5.119695e+03         Negative               0.001517\n",
      "     vflt           0.2       1365.00       9.502098e+02         Positive               0.000907\n",
      " freeswap           2.0    2243187.00       2.030841e+06         Positive               0.000572\n",
      "    rchar         278.0    2526649.00       1.033471e+06         Positive               0.000267\n",
      "    lread           0.0       1845.00       5.615831e+02         Positive               0.000229\n",
      "    wchar        1498.0    1801623.00       1.243087e+05         Positive               0.000162\n",
      "    pgout           0.0         81.44       3.008087e+01         Positive               0.000156\n",
      "    sread           6.0       5318.00       4.862029e+02         Positive               0.000132\n",
      "     exec           0.0         59.56       1.175078e+01         Positive               0.000100\n",
      "    ppgin           0.0        292.61       1.509365e+02         Negative               0.000088\n",
      "   pgfree           0.0        523.00       2.826878e+02         Negative               0.000075\n",
      "   lwrite           0.0        575.00       5.066463e+02         Positive               0.000030\n",
      "    scall         109.0      12493.00       5.504199e+03         Negative               0.000025\n",
      "   swrite           7.0       5456.00       3.376216e+02         Positive               0.000020\n",
      "==================================================================================\n",
      "\n",
      "üìÑ Saved Control Surface to: titan_os_control_surface.csv\n",
      "üì¶ Saved JSON Profile to: titan_os_profile.json\n"
     ]
    }
   ],
   "source": [
    "# ==================================================================================================\n",
    "# üåå TITAN OS: \"PENROSE RING\" GRAND UNIFIED OPTIMIZATION PROTOCOL (v2.1 FINAL)\n",
    "# ==================================================================================================\n",
    "# PURPOSE:  Create the ultimate CPU Operating System Blueprint using Real-World Data.\n",
    "# DATA:     1. OpenML 197 'cpu_act' (8,192 OS Kernel snapshots)\n",
    "#           2. OpenML 533 (CPU Performance Regression benchmarks)\n",
    "#           3. OpenML 44148 (Exotic Superconductor Physics for Hardware Layer)\n",
    "# STACK:    Full 5-Stage Titan Suite (Validation -> Discovery -> Attribution -> Causal -> Optimization)\n",
    "# OUTPUTS:  Developer-Ready 'Control Surface' CSV & 'OS Profile' JSON.\n",
    "# ==================================================================================================\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import warnings\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import networkx as nx\n",
    "import xgboost as xgb\n",
    "from typing import Dict, List, Tuple\n",
    "from dataclasses import dataclass\n",
    "from tqdm.auto import tqdm\n",
    "from scipy.stats import ks_2samp, chisquare\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.ensemble import IsolationForest, RandomForestRegressor\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# GPU Configuration\n",
    "warnings.filterwarnings('ignore')\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"üöÄ SYSTEM ONLINE: TITAN OS OPTIMIZER | DEVICE: {DEVICE}\")\n",
    "\n",
    "# ==================================================================================================\n",
    "# 1. TITAN VALIDATION FRAMEWORK (TVF) - MANIFOLD EDITION\n",
    "# ==================================================================================================\n",
    "@dataclass\n",
    "class TVFConfig:\n",
    "    drift_alpha: float = 0.05\n",
    "    reconstruction_error_threshold: float = 0.15\n",
    "    min_explained_variance_ratio: float = 0.85\n",
    "    iforest_contamination: float = 0.03\n",
    "\n",
    "class TitanValidationFramework:\n",
    "    def __init__(self, reference_data: pd.DataFrame, config: TVFConfig = None):\n",
    "        self.config = config or TVFConfig()\n",
    "        self.reference = reference_data.copy()\n",
    "        self.num_cols = self.reference.select_dtypes(include=[np.number]).columns.tolist()\n",
    "        self.scaler = StandardScaler()\n",
    "        \n",
    "        print(\"   [TVF] Learning Baseline Structure (Manifold & Anomalies)...\")\n",
    "        if len(self.num_cols) > 0:\n",
    "            X = self.scaler.fit_transform(self.reference[self.num_cols].fillna(0))\n",
    "            \n",
    "            # Learn the \"Safe Operating Manifold\" via PCA\n",
    "            self.pca = PCA(n_components=0.95)\n",
    "            self.pca.fit(X)\n",
    "            X_recon = self.pca.inverse_transform(self.pca.transform(X))\n",
    "            self.ref_recon_error = np.mean(np.square(X - X_recon))\n",
    "            \n",
    "            # Learn \"Safe Operating Envelope\" via Isolation Forest\n",
    "            self.iforest = IsolationForest(\n",
    "                contamination=self.config.iforest_contamination, n_jobs=-1, random_state=42\n",
    "            )\n",
    "            self.iforest.fit(X)\n",
    "        else:\n",
    "            self.pca = None\n",
    "            self.iforest = None\n",
    "            self.ref_recon_error = 0.0\n",
    "\n",
    "    def validate(self, new_data: pd.DataFrame) -> Tuple[bool, pd.DataFrame]:\n",
    "        report_rows = []\n",
    "        # Check Integrity\n",
    "        missing = set(self.reference.columns) - set(new_data.columns)\n",
    "        if missing:\n",
    "            report_rows.append({\"Module\": \"Integrity\", \"Status\": \"RED\", \"Reason\": f\"Missing: {list(missing)[:3]}\"})\n",
    "        \n",
    "        if self.pca is not None and len(self.num_cols) > 0:\n",
    "            X = self.scaler.transform(new_data[self.num_cols].fillna(0))\n",
    "            \n",
    "            # Check Manifold Drift\n",
    "            X_recon = self.pca.inverse_transform(self.pca.transform(X))\n",
    "            curr_error = np.mean(np.square(X - X_recon))\n",
    "            ratio = curr_error / max(self.ref_recon_error, 1e-9)\n",
    "            if ratio > (1 + self.config.reconstruction_error_threshold):\n",
    "                report_rows.append({\"Module\": \"Structure\", \"Status\": \"RED\", \"Reason\": f\"Manifold Drift (Err: {ratio:.2f}x)\"})\n",
    "            \n",
    "            # Check Anomalies\n",
    "            if self.iforest is not None:\n",
    "                preds = self.iforest.predict(X)\n",
    "                rate = (preds == -1).mean()\n",
    "                if rate > self.config.iforest_contamination * 3:\n",
    "                    report_rows.append({\"Module\": \"Anomalies\", \"Status\": \"RED\", \"Reason\": f\"High Anomaly Rate ({rate:.1%})\"})\n",
    "\n",
    "        report = pd.DataFrame(report_rows) if report_rows else pd.DataFrame(\n",
    "            [{\"Module\": \"Global\", \"Status\": \"GREEN\", \"Reason\": \"All Systems Nominal\"}]\n",
    "        )\n",
    "        return len(report_rows) == 0, report\n",
    "\n",
    "    def manifold_penalty(self, candidate_df: pd.DataFrame) -> float:\n",
    "        \"\"\"Calculates how 'unrealistic' a proposed OS config is.\"\"\"\n",
    "        if self.pca is None or len(self.num_cols) == 0: return 0.0\n",
    "        \n",
    "        # Ensure alignment\n",
    "        df = candidate_df.copy()\n",
    "        for c in self.num_cols:\n",
    "            if c not in df.columns: df[c] = 0.0 # Zero fill missing\n",
    "            \n",
    "        X = self.scaler.transform(df[self.num_cols].fillna(0))\n",
    "        X_recon = self.pca.inverse_transform(self.pca.transform(X))\n",
    "        \n",
    "        # Reconstruction error ratio relative to baseline\n",
    "        recon_ratio = np.mean((X - X_recon) ** 2) / max(self.ref_recon_error, 1e-9)\n",
    "        \n",
    "        # Penalty applies only if we drift significantly outside the baseline manifold\n",
    "        penalty = max(0.0, recon_ratio - 1.2) \n",
    "        return float(penalty)\n",
    "\n",
    "# ==================================================================================================\n",
    "# 2. UNIFIED DISCOVERY ENGINE (UDE)\n",
    "# ==================================================================================================\n",
    "class UnifiedDiscoveryEngine:\n",
    "    def __init__(self, df, target_col):\n",
    "        self.raw_df = df.copy()\n",
    "        self.target = target_col\n",
    "        self.features = [c for c in df.columns if c != target_col]\n",
    "        print(f\"üîç UDE ONLINE. Target: '{self.target}'\")\n",
    "\n",
    "    def scan_physics(self):\n",
    "        print(\"\\n>> [UDE] SCANNING NON-LINEAR PHYSICS...\")\n",
    "        X, y = self.raw_df[self.features], self.raw_df[self.target]\n",
    "        model = xgb.XGBRegressor(n_estimators=200, max_depth=5, n_jobs=-1, random_state=42)\n",
    "        model.fit(X, y)\n",
    "        imp = pd.Series(model.feature_importances_, index=self.features).sort_values(ascending=False)\n",
    "        print(f\"   Baseline R¬≤: {model.score(X, y):.4f}\")\n",
    "        return imp\n",
    "\n",
    "    def detect_redundancy(self, top_features, threshold=0.90):\n",
    "        print(\"\\n>> [UDE] PURGING REDUNDANT DIMENSIONS...\")\n",
    "        survivors = []\n",
    "        for f in top_features:\n",
    "            is_redundant = False\n",
    "            if survivors:\n",
    "                X_surv = self.raw_df[survivors]\n",
    "                y_feat = self.raw_df[f]\n",
    "                # Can we predict this feature from the ones we already kept?\n",
    "                r2 = RandomForestRegressor(\n",
    "                    n_estimators=40, max_depth=6, n_jobs=-1, random_state=42\n",
    "                ).fit(X_surv, y_feat).score(X_surv, y_feat)\n",
    "                \n",
    "                if r2 > threshold:\n",
    "                    print(f\"   ‚öîÔ∏è Killed '{f}' (Redundant with Survivors, R¬≤={r2:.2f})\")\n",
    "                    is_redundant = True\n",
    "            if not is_redundant:\n",
    "                survivors.append(f)\n",
    "        return survivors\n",
    "\n",
    "# ==================================================================================================\n",
    "# 3. UNIVERSAL ATTRIBUTION VALIDATOR (UAV)\n",
    "# ==================================================================================================\n",
    "class UniversalAttributionValidator:\n",
    "    def __init__(self, X_df, y_series):\n",
    "        self.X_vals = X_df.values.astype(np.float32)\n",
    "        self.y_vals = y_series.values.astype(np.float32)\n",
    "        self.cols = X_df.columns.tolist()\n",
    "        self.X_t = torch.from_numpy(self.X_vals).to(DEVICE)\n",
    "        self.y_t = torch.from_numpy(self.y_vals).reshape(-1, 1).to(DEVICE)\n",
    "        self._train_proxy()\n",
    "\n",
    "    def _train_proxy(self):\n",
    "        print(f\"\\n‚öñÔ∏è [UAV] TRAINING DIFFERENTIABLE SURROGATE...\")\n",
    "        d_in = self.X_t.shape[1]\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(d_in, 128), nn.SiLU(), nn.Dropout(0.1),\n",
    "            nn.Linear(128, 64), nn.SiLU(), nn.Linear(64, 1)\n",
    "        ).to(DEVICE)\n",
    "        opt = torch.optim.Adam(self.model.parameters(), lr=0.002)\n",
    "        loss_fn = nn.MSELoss()\n",
    "        \n",
    "        # Fast convergence training\n",
    "        pbar = tqdm(range(400), desc=\"   Training Surrogate\", leave=False)\n",
    "        for _ in pbar:\n",
    "            opt.zero_grad()\n",
    "            pred = self.model(self.X_t + torch.randn_like(self.X_t)*0.01) # Add noise for robustness\n",
    "            loss = loss_fn(pred, self.y_t)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "\n",
    "    def compute_integrated_gradients(self, n_steps=50):\n",
    "        print(\"   [UAV] Calculating Gradient Flows (Sensitivity)...\")\n",
    "        baseline = torch.mean(self.X_t, dim=0, keepdim=True)\n",
    "        batch = self.X_t[:min(2000, self.X_t.shape[0])] # Sample for speed\n",
    "        grads_acc = torch.zeros_like(batch)\n",
    "        \n",
    "        for alpha in np.linspace(0, 1, n_steps):\n",
    "            x_step = baseline + alpha * (batch - baseline)\n",
    "            x_step.requires_grad = True\n",
    "            out = self.model(x_step).sum()\n",
    "            out.backward()\n",
    "            grads_acc += x_step.grad\n",
    "            \n",
    "        avg_grads = grads_acc / n_steps\n",
    "        attr = (batch - baseline) * avg_grads\n",
    "        return pd.Series(attr.detach().cpu().numpy().mean(axis=0), index=self.cols).sort_values(ascending=False)\n",
    "\n",
    "# ==================================================================================================\n",
    "# 4. PLATINUM CAUSAL INTERVENTION ENGINE\n",
    "# ==================================================================================================\n",
    "class PlatinumCausalEngine:\n",
    "    def __init__(self, df, graph_edges):\n",
    "        self.df = df\n",
    "        self.G = nx.DiGraph(graph_edges)\n",
    "        self.models = {}\n",
    "        self._fit_mechanisms()\n",
    "\n",
    "    def _fit_mechanisms(self):\n",
    "        print(\"\\n‚öôÔ∏è [UIF] FITTING CAUSAL MECHANISMS...\")\n",
    "        for node in self.G.nodes():\n",
    "            parents = list(self.G.predecessors(node))\n",
    "            if parents:\n",
    "                self.models[node] = xgb.XGBRegressor(\n",
    "                    n_estimators=80, max_depth=4, n_jobs=-1\n",
    "                ).fit(self.df[parents], self.df[node])\n",
    "\n",
    "    def simulate(self, intervention: dict, target: str):\n",
    "        sim_df = self.df.sample(n=min(1500, len(self.df)), replace=True).copy()\n",
    "        \n",
    "        # 1. Apply Intervention\n",
    "        for node, val in intervention.items():\n",
    "            sim_df[node] = val\n",
    "            \n",
    "        # 2. Propagate through Graph\n",
    "        sorted_nodes = list(nx.topological_sort(self.G))\n",
    "        for node in sorted_nodes:\n",
    "            if node in intervention: continue\n",
    "            parents = list(self.G.predecessors(node))\n",
    "            if parents:\n",
    "                sim_df[node] = self.models[node].predict(sim_df[parents])\n",
    "                \n",
    "        return sim_df[target].mean(), sim_df[target].std()\n",
    "\n",
    "# ==================================================================================================\n",
    "# 5. UNIFIED OPTIMIZATION FRAMEWORK\n",
    "# ==================================================================================================\n",
    "class UnifiedOptimizer:\n",
    "    def __init__(self, objective_func, bounds):\n",
    "        self.func = objective_func\n",
    "        self.bounds = bounds\n",
    "\n",
    "    def optimize_genetic(self, pop_size=60, generations=20):\n",
    "        print(\"üß¨ [UOF] RUNNING GENETIC EVOLUTION...\")\n",
    "        from scipy.optimize import differential_evolution\n",
    "        \n",
    "        def wrapper(x):\n",
    "            params = {k: v for k, v in zip(self.bounds.keys(), x)}\n",
    "            return -self.func(**params) # Minimize negative = Maximize\n",
    "        \n",
    "        result = differential_evolution(\n",
    "            wrapper, \n",
    "            bounds=list(self.bounds.values()), \n",
    "            maxiter=generations, \n",
    "            popsize=max(6, pop_size // 10),\n",
    "            workers=1\n",
    "        )\n",
    "        return {k: v for k, v in zip(self.bounds.keys(), result.x)}, -result.fun\n",
    "\n",
    "# ==================================================================================================\n",
    "# üöÄ MAIN EXECUTION PROTOCOL\n",
    "# ==================================================================================================\n",
    "def main():\n",
    "    print(\"==================================================================================\")\n",
    "    print(\"üåå INITIATING GRAND UNIFIED DATA INGESTION (REAL PHYSICS, EXPANDED)\")\n",
    "    print(\"==================================================================================\")\n",
    "    \n",
    "    # --------------------------------------------------------------------------------------------\n",
    "    # A. DATA INGESTION\n",
    "    # --------------------------------------------------------------------------------------------\n",
    "    # 1. OS KERNEL DATA (Workload: System Calls, I/O, Paging)\n",
    "    print(\">> [SOURCE 1] Fetching OS Kernel Data (Delve: 'cpu_act', ID 197)...\")\n",
    "    os_data = fetch_openml(data_id=197, as_frame=True, parser='auto').frame\n",
    "    print(f\"   ‚úì OS Data Secured: {os_data.shape} - (System Calls, I/O, Interrupts)\")\n",
    "    \n",
    "    # 2. CPU PERFORMANCE REGRESSION (Benchmarks)\n",
    "    print(\">> [SOURCE 2] Fetching CPU Performance Regression Data (ID 533)...\")\n",
    "    try:\n",
    "        cpu_perf = fetch_openml(data_id=533, as_frame=True, parser='auto').frame\n",
    "        print(f\"   ‚úì CPU Perf Data Secured: {cpu_perf.shape}\")\n",
    "        # Rename to avoid collisions\n",
    "        cpu_perf_numeric = cpu_perf.select_dtypes(include=[np.number])\n",
    "        cpu_perf_numeric.columns = [f\"CPUPerf_{c}\" for c in cpu_perf_numeric.columns]\n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ö†Ô∏è CPU Perf dataset unavailable ({e}), proceeding with OS data only.\")\n",
    "        cpu_perf_numeric = pd.DataFrame()\n",
    "    \n",
    "    # 3. EXOTIC HARDWARE DATA (Superconductors for 'Future Material' Simulation)\n",
    "    print(\">> [SOURCE 3] Fetching Exotic Hardware Data (Superconduct, ID 44148)...\")\n",
    "    hw_full = fetch_openml(data_id=44148, as_frame=True, parser='auto').frame\n",
    "    print(f\"   ‚úì Hardware Data Secured: {hw_full.shape} - (81 features + critical_temp)\")\n",
    "    \n",
    "    hw_features = hw_full.iloc[:, :-1]\n",
    "    hw_target = hw_full.iloc[:, -1]\n",
    "    \n",
    "    # Take a wider slice of hardware features (Top 24)\n",
    "    n_hw_feats = min(24, hw_features.shape[1])\n",
    "    hw_subset = hw_features.iloc[:, :n_hw_feats].copy()\n",
    "    hw_subset.columns = [f\"HW_Feat_{i+1}\" for i in range(n_hw_feats)]\n",
    "    hw_subset[\"HW_Thermal_Limit\"] = hw_target.values\n",
    "\n",
    "    # --------------------------------------------------------------------------------------------\n",
    "    # B. FUSION & PREPROCESSING\n",
    "    # --------------------------------------------------------------------------------------------\n",
    "    print(\"\\n>> [FUSION] Merging OS + CPUPerf + Hardware into 'Penrose Ring' Matrix...\")\n",
    "    n_samples = min(len(os_data), len(hw_subset), 10000)\n",
    "    \n",
    "    df_os = os_data.sample(n_samples, random_state=42).reset_index(drop=True)\n",
    "    df_hw = hw_subset.sample(n_samples, random_state=42).reset_index(drop=True)\n",
    "    \n",
    "    if cpu_perf_numeric.empty:\n",
    "        df_main = pd.concat([df_os, df_hw], axis=1)\n",
    "    else:\n",
    "        cpu_perf_slice = cpu_perf_numeric.sample(n_samples, replace=True, random_state=42).reset_index(drop=True)\n",
    "        df_main = pd.concat([df_os, cpu_perf_slice, df_hw], axis=1)\n",
    "    \n",
    "    # Target: 'usr' (User CPU Time - Goal is to Maximize useful work, Minimize 'sys' overhead)\n",
    "    target_col = 'usr'\n",
    "    if target_col not in df_main.columns:\n",
    "        raise RuntimeError(f\"Target column '{target_col}' not found. Available: {df_main.columns.tolist()[:30]}\")\n",
    "    \n",
    "    # Keep Raw Copy for Final Reporting\n",
    "    df_raw = df_main.copy()\n",
    "    \n",
    "    # Normalize [0,1] for Neural Nets & Optimization\n",
    "    scaler = MinMaxScaler()\n",
    "    df_main = pd.DataFrame(scaler.fit_transform(df_main), columns=df_main.columns)\n",
    "    print(f\"‚úì FUSION COMPLETE. Matrix: {df_main.shape}\")\n",
    "\n",
    "    # --------------------------------------------------------------------------------------------\n",
    "    # C. EXECUTE TITAN STACK\n",
    "    # --------------------------------------------------------------------------------------------\n",
    "    \n",
    "    # PHASE 1: VALIDATION\n",
    "    print(\"\\n[PHASE 1] VALIDATION SCAN\")\n",
    "    tvf = TitanValidationFramework(df_main)\n",
    "    passed, report = tvf.validate(df_main)\n",
    "    print(report)\n",
    "\n",
    "    # PHASE 2: DISCOVERY\n",
    "    print(\"\\n[PHASE 2] DISCOVERING INFLUENTIAL PARAMETERS\")\n",
    "    ude = UnifiedDiscoveryEngine(df_main, target_col)\n",
    "    importances = ude.scan_physics()\n",
    "    \n",
    "    # Take top 20 drivers\n",
    "    top_drivers = importances.head(20).index.tolist()\n",
    "    print(f\"   Top Drivers: {top_drivers}\")\n",
    "    \n",
    "    # Clean Redundancy\n",
    "    clean_drivers = ude.detect_redundancy(top_drivers)\n",
    "    print(f\"   Unique Control Knobs: {clean_drivers}\")\n",
    "\n",
    "    # PHASE 3: ATTRIBUTION\n",
    "    print(\"\\n[PHASE 3] DECODING PHYSICS (Attribution)\")\n",
    "    uav = UniversalAttributionValidator(df_main[clean_drivers], df_main[target_col])\n",
    "    attr_scores = uav.compute_integrated_gradients()\n",
    "    print(\"\\nüèÜ PARAMETER IMPACT (Sensitivity):\")\n",
    "    print(attr_scores)\n",
    "\n",
    "    # PHASE 4: CAUSAL SIMULATION\n",
    "    print(\"\\n[PHASE 4] SIMULATING INTERVENTIONS\")\n",
    "    # Build Graph: HW Features -> System Calls -> User CPU\n",
    "    edges = []\n",
    "    if ('HW_Feat_1' in clean_drivers) and ('scall' in clean_drivers):\n",
    "        edges.append(('HW_Feat_1', 'scall'))\n",
    "    for d in clean_drivers:\n",
    "        if d != target_col:\n",
    "            edges.append((d, target_col))\n",
    "    \n",
    "    pce = PlatinumCausalEngine(df_main[clean_drivers + [target_col]], edges)\n",
    "    \n",
    "    # Test Scenario: \"Kernel Bypass\" (Minimizing System Calls)\n",
    "    if 'scall' in clean_drivers:\n",
    "        print(\">> Simulating 'Kernel Bypass' (scall = 0.1)...\")\n",
    "        mu, std = pce.simulate({'scall': 0.1}, target=target_col)\n",
    "        print(f\"   Predicted User CPU (normalized): {mu:.3f} (¬±{std:.3f})\")\n",
    "\n",
    "    # PHASE 5: OPTIMIZATION (With Manifold Regularization)\n",
    "    print(\"\\n[PHASE 5] PENROSE RING OPTIMIZATION (Regularized)\")\n",
    "    \n",
    "    def objective(**kwargs):\n",
    "        # 1. Build Vector\n",
    "        vec = [kwargs.get(col, 0.5) for col in clean_drivers]\n",
    "        t_vec = torch.tensor([vec], dtype=torch.float32).to(DEVICE)\n",
    "        \n",
    "        # 2. Get Raw Performance Score from Surrogate\n",
    "        with torch.no_grad():\n",
    "            base_score = float(uav.model(t_vec).item())\n",
    "        \n",
    "        # 3. Calculate Manifold Penalty (Is this config realistic?)\n",
    "        candidate = {c: 0.5 for c in df_main.columns}\n",
    "        for k, v in zip(clean_drivers, vec):\n",
    "            candidate[k] = v\n",
    "        cand_df = pd.DataFrame([candidate])\n",
    "        penalty = tvf.manifold_penalty(cand_df)\n",
    "        \n",
    "        # 4. Return Regularized Score\n",
    "        # Penalty weight 0.1 keeps us inside the valid operating envelope\n",
    "        return base_score - 0.1 * penalty\n",
    "\n",
    "    bounds = {k: (0.0, 1.0) for k in clean_drivers}\n",
    "    optimizer = UnifiedOptimizer(objective, bounds)\n",
    "    best_cfg, best_val = optimizer.optimize_genetic(generations=15)\n",
    "\n",
    "    # --------------------------------------------------------------------------------------------\n",
    "    # D. EXPORT & REPORTING\n",
    "    # --------------------------------------------------------------------------------------------\n",
    "    print(\"\\n[PHASE 6] EXPORTING DEVELOPER BLUEPRINT\")\n",
    "    \n",
    "    # 1. Denormalize Best Config to Original Units\n",
    "    best_row_norm = {c: 0.5 for c in df_main.columns} # Default baseline\n",
    "    for k, v in best_cfg.items():\n",
    "        best_row_norm[k] = v\n",
    "        \n",
    "    best_row_norm_df = pd.DataFrame([best_row_norm])\n",
    "    best_row_raw_vals = scaler.inverse_transform(best_row_norm_df[df_main.columns])\n",
    "    best_row_raw = pd.Series(best_row_raw_vals[0], index=df_main.columns)\n",
    "    \n",
    "    # 2. Build Summary Table\n",
    "    summary_rows = []\n",
    "    for knob in clean_drivers:\n",
    "        col_idx = list(df_main.columns).index(knob)\n",
    "        col_min = scaler.data_min_[col_idx]\n",
    "        col_max = scaler.data_max_[col_idx]\n",
    "        \n",
    "        recommended = best_row_raw[knob]\n",
    "        sensitivity = attr_scores.get(knob, 0.0)\n",
    "        \n",
    "        summary_rows.append({\n",
    "            \"Parameter\": knob,\n",
    "            \"Original_Min\": col_min,\n",
    "            \"Original_Max\": col_max,\n",
    "            \"Recommended_Value\": recommended,\n",
    "            \"Sensitivity_Sign\": \"Positive\" if sensitivity > 0 else \"Negative\",\n",
    "            \"Sensitivity_Magnitude\": float(abs(sensitivity))\n",
    "        })\n",
    "    \n",
    "    summary_df = pd.DataFrame(summary_rows).sort_values(\"Sensitivity_Magnitude\", ascending=False)\n",
    "    \n",
    "    # 3. Print Final Report\n",
    "    print(\"\\n==================================================================================\")\n",
    "    print(\"üèÅ FINAL SYSTEM BLUEPRINT (Original Units)\")\n",
    "    print(\"==================================================================================\")\n",
    "    print(f\"üåü MAX ACHIEVABLE USER CPU (normalized surrogate): {best_val:.2%}\")\n",
    "    print(\"\\nüîß OPTIMAL CONTROL SURFACE (Top by Sensitivity):\")\n",
    "    print(summary_df.head(20).to_string(index=False))\n",
    "    print(\"==================================================================================\")\n",
    "\n",
    "    # 4. Generate JSON/CSV Artifacts\n",
    "    # CSV\n",
    "    summary_df.to_csv(\"titan_os_control_surface.csv\", index=False)\n",
    "    print(f\"\\nüìÑ Saved Control Surface to: titan_os_control_surface.csv\")\n",
    "    \n",
    "    # JSON\n",
    "    os_spec = {\n",
    "        \"meta\": {\n",
    "            \"version\": \"titan_os_penrose_v2\",\n",
    "            \"description\": \"Unified OS+Hardware Optimization Profile\",\n",
    "            \"target_metric\": target_col,\n",
    "            \"normalized_score\": best_val\n",
    "        },\n",
    "        \"controls\": [],\n",
    "        \"profiles\": {\n",
    "            \"baseline_normalized\": {c: 0.5 for c in df_main.columns},\n",
    "            \"optimized_normalized\": {c: best_cfg.get(c, 0.5) for c in df_main.columns}\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    for _, row in summary_df.iterrows():\n",
    "        os_spec[\"controls\"].append({\n",
    "            \"name\": row[\"Parameter\"],\n",
    "            \"recommended\": float(row[\"Recommended_Value\"]),\n",
    "            \"min\": float(row[\"Original_Min\"]),\n",
    "            \"max\": float(row[\"Original_Max\"]),\n",
    "            \"impact\": float(row[\"Sensitivity_Magnitude\"])\n",
    "        })\n",
    "        \n",
    "    with open(\"titan_os_profile.json\", \"w\") as f:\n",
    "        json.dump(os_spec, f, indent=2)\n",
    "    print(f\"üì¶ Saved JSON Profile to: titan_os_profile.json\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d3a6d58",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-22T23:34:10.074979Z",
     "iopub.status.busy": "2026-01-22T23:34:10.074600Z",
     "iopub.status.idle": "2026-01-22T23:34:21.963413Z",
     "shell.execute_reply": "2026-01-22T23:34:21.962423Z"
    },
    "papermill": {
     "duration": 11.897724,
     "end_time": "2026-01-22T23:34:21.965450",
     "exception": false,
     "start_time": "2026-01-22T23:34:10.067726",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ SYSTEM ONLINE: TITAN GPU OPTIMIZER | DEVICE: cuda\n",
      "==================================================================================\n",
      "‚ö° INITIATING SYNTHETIC GPU KERNEL OPTIMIZATION PIPELINE\n",
      "==================================================================================\n",
      ">> [SOURCE] Generating Synthetic GPU Kernel Data...\n",
      "   ‚úì Synthetic Kernel Data: (20000, 16)\n",
      "\n",
      "[PHASE 1] VALIDATION SCAN (GPU)\n",
      "   [TVF-GPU] Learning Baseline Structure (Manifold & Anomalies)...\n",
      "   Module Status               Reason\n",
      "0  Global  GREEN  All Systems Nominal\n",
      "\n",
      "[PHASE 2] DISCOVERING GPU KERNEL DRIVERS\n",
      "üîç UDE-GPU ONLINE. Target: 'Perf_Score'\n",
      "\n",
      ">> [UDE-GPU] SCANNING SYNTHETIC KERNEL PHYSICS...\n",
      "   Baseline R¬≤: 0.9831\n",
      "   Top Drivers: ['tensor_cores', 'use_f16', 'use_tex', 'vwidth', 'reg_per_thread', 'smem_kb', 'branch_divergence', 'unroll', 'block_y', 'block_x', 'mem_stride', 'l2_hits', 'grid_y', 'grid_x', 'use_f32']\n",
      "\n",
      ">> [UDE-GPU] PURGING REDUNDANT DIMENSIONS...\n",
      "   ‚öîÔ∏è Killed 'use_f32' (Redundant with Survivors, R¬≤=1.00)\n",
      "   Unique Kernel Knobs: ['tensor_cores', 'use_f16', 'use_tex', 'vwidth', 'reg_per_thread', 'smem_kb', 'branch_divergence', 'unroll', 'block_y', 'block_x', 'mem_stride', 'l2_hits', 'grid_y', 'grid_x']\n",
      "\n",
      "[PHASE 3] DECODING KERNEL PHYSICS (Attribution)\n",
      "\n",
      "‚öñÔ∏è [UAV-GPU] TRAINING DIFFERENTIABLE SURROGATE...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "786e17d9ce634fd296cf9b05b5ca5cce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "   Training GPU Surrogate:   0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   [UAV-GPU] Calculating Gradient Flows (Sensitivity)...\n",
      "\n",
      "üèÜ KERNEL PARAMETER IMPACT (Sensitivity):\n",
      "use_f16              1.180712e-02\n",
      "branch_divergence    5.223335e-03\n",
      "tensor_cores         1.451301e-03\n",
      "unroll               1.289340e-03\n",
      "smem_kb              2.601430e-04\n",
      "reg_per_thread       7.069767e-07\n",
      "mem_stride          -3.649417e-05\n",
      "l2_hits             -1.554212e-04\n",
      "grid_y              -2.838218e-04\n",
      "grid_x              -3.251331e-04\n",
      "use_tex             -3.804266e-04\n",
      "block_x             -1.089204e-03\n",
      "block_y             -1.921759e-03\n",
      "vwidth              -9.609383e-03\n",
      "dtype: float32\n",
      "\n",
      "[PHASE 4] SIMULATING INTERVENTIONS\n",
      "\n",
      "‚öôÔ∏è [UIF-GPU] FITTING KERNEL CAUSAL MECHANISMS...\n",
      ">> Simulating 'Max-Out' Strategy on {'use_f16': 1.0, 'branch_divergence': 1.0, 'tensor_cores': 1.0} ...\n",
      "   Predicted Perf_Score (normalized): 0.0661 (¬±0.0811)\n",
      "\n",
      "[PHASE 5] GPU KERNEL OPTIMIZATION (Regularized)\n",
      "üß¨ [UOF-GPU] RUNNING GENETIC EVOLUTION...\n",
      "\n",
      "[PHASE 6] EXPORTING GPU KERNEL BLUEPRINT\n",
      "\n",
      "==================================================================================\n",
      "üèÅ FINAL GPU KERNEL BLUEPRINT (Original Units, target=Perf_Score)\n",
      "==================================================================================\n",
      "üåü MAX ACHIEVABLE Perf_Score (normalized surrogate): 0.4301\n",
      "\n",
      "üîß OPTIMAL GPU CONFIG (Top by Sensitivity):\n",
      "        Parameter  Original_Min  Original_Max  Recommended_Value Sensitivity_Sign  Sensitivity_Magnitude\n",
      "          use_f16      0.000000      1.000000           0.881521         Positive           1.180712e-02\n",
      "           vwidth      1.000000      8.000000           7.700710         Negative           9.609383e-03\n",
      "branch_divergence      0.000265      0.999954           0.030898         Positive           5.223335e-03\n",
      "          block_y      1.000000     32.000000          28.960377         Negative           1.921759e-03\n",
      "     tensor_cores      0.000000      1.000000           0.872564         Positive           1.451301e-03\n",
      "           unroll      1.000000      8.000000           6.632461         Positive           1.289340e-03\n",
      "          block_x     32.000000   1024.000000         739.865930         Negative           1.089204e-03\n",
      "          use_tex      0.000000      1.000000           0.998082         Negative           3.804266e-04\n",
      "           grid_x     16.000000   2048.000000          37.190425         Negative           3.251331e-04\n",
      "           grid_y      1.000000    128.000000          13.960887         Negative           2.838218e-04\n",
      "          smem_kb      0.000000     64.000000           2.281141         Positive           2.601430e-04\n",
      "          l2_hits      0.078344      0.997901           0.620920         Negative           1.554212e-04\n",
      "       mem_stride      1.000000      8.000000           2.975600         Negative           3.649417e-05\n",
      "   reg_per_thread     16.000000    128.000000          23.473343         Positive           7.069767e-07\n",
      "==================================================================================\n",
      "üìÑ Saved GPU Control Surface to: titan_gpu_control_surface.csv\n",
      "üì¶ Saved GPU JSON Profile to: titan_gpu_profile.json\n"
     ]
    }
   ],
   "source": [
    "# ==================================================================================================\n",
    "# ‚ö° TITAN GPU: SYNTHETIC KERNEL OPTIMIZATION PROTOCOL (Cell 2, Self-contained)\n",
    "# ==================================================================================================\n",
    "# PURPOSE: Mirror CPU Cell 1 for GPU using a synthetic but realistic kernel-performance dataset.\n",
    "# DATA:    Generated in-notebook: grid/block sizes, memory tiling, vector widths, precision modes.\n",
    "# TARGET:  Perf_Score ~ throughput (higher is better).\n",
    "# STACK:   TVF, UDE, UAV, UIF, UOF.\n",
    "# OUTPUTS: titan_gpu_control_surface.csv, titan_gpu_profile.json\n",
    "# ==================================================================================================\n",
    "\n",
    "import os\n",
    "import json\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import networkx as nx\n",
    "import xgboost as xgb\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, List, Tuple\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.ensemble import IsolationForest, RandomForestRegressor\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"üöÄ SYSTEM ONLINE: TITAN GPU OPTIMIZER | DEVICE: {DEVICE}\")\n",
    "\n",
    "# ==================================================================================================\n",
    "# 0. SYNTHETIC GPU KERNEL DATA GENERATOR\n",
    "# ==================================================================================================\n",
    "def generate_gpu_kernel_data(n_samples: int = 20000, seed: int = 42) -> pd.DataFrame:\n",
    "    rng = np.random.default_rng(seed)\n",
    "    \n",
    "    block_x = rng.integers(32, 1025, size=n_samples)\n",
    "    block_y = rng.integers(1, 33, size=n_samples)\n",
    "    grid_x  = rng.integers(16, 2049, size=n_samples)\n",
    "    grid_y  = rng.integers(1, 129, size=n_samples)\n",
    "    smem_kb = rng.integers(0, 65, size=n_samples)\n",
    "    reg_per_thread = rng.integers(16, 129, size=n_samples)\n",
    "\n",
    "    vwidth = rng.choice([1, 2, 4, 8], size=n_samples)\n",
    "    unroll = rng.choice([1, 2, 4, 8], size=n_samples)\n",
    "    use_tex = rng.integers(0, 2, size=n_samples)\n",
    "    use_f16 = rng.integers(0, 2, size=n_samples)\n",
    "    use_f32 = 1 - use_f16\n",
    "\n",
    "    # New knobs\n",
    "    mem_stride = rng.choice([1, 2, 4, 8], size=n_samples)\n",
    "    branch_divergence = rng.random(size=n_samples)          # 0..1\n",
    "    l2_hits = rng.beta(5, 2, size=n_samples)                # bias to high hit rate\n",
    "    tensor_cores = rng.integers(0, 2, size=n_samples)\n",
    "\n",
    "    occupancy = np.minimum(1.0,\n",
    "        (block_x * block_y) / 1024.0 *\n",
    "        (48.0 / np.maximum(16, reg_per_thread)) *\n",
    "        (1.0 - smem_kb / 96.0)\n",
    "    )\n",
    "    occupancy = np.clip(occupancy, 0.0, 1.0)\n",
    "\n",
    "    mem_eff = np.minimum(1.0, vwidth / 4.0) * (0.5 + 0.5 * use_tex)\n",
    "    mem_eff *= (1.0 - 0.15 * (mem_stride > 2))             # penalty for bad stride\n",
    "    mem_eff *= (0.7 + 0.3 * l2_hits)                       # more L2 hits = better\n",
    "\n",
    "    math_throughput = 0.4 + 0.4 * use_f16 + 0.2 * (unroll / 8.0)\n",
    "    math_throughput *= (1.0 + 0.3 * (tensor_cores * use_f16))\n",
    "\n",
    "    base_perf = occupancy * (0.4 * mem_eff + 0.6 * math_throughput)\n",
    "\n",
    "    penalty = 0.0\n",
    "    penalty += (reg_per_thread > 96) * 0.2\n",
    "    penalty += (smem_kb > 48) * 0.2\n",
    "    penalty += ((block_x * block_y) > 1024) * 0.5\n",
    "    penalty += 0.3 * branch_divergence                         # divergence hurts\n",
    "\n",
    "    perf_score = np.maximum(0.0, base_perf - penalty + rng.normal(0, 0.02, size=n_samples))\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        \"block_x\": block_x,\n",
    "        \"block_y\": block_y,\n",
    "        \"grid_x\": grid_x,\n",
    "        \"grid_y\": grid_y,\n",
    "        \"smem_kb\": smem_kb,\n",
    "        \"reg_per_thread\": reg_per_thread,\n",
    "        \"vwidth\": vwidth,\n",
    "        \"unroll\": unroll,\n",
    "        \"use_tex\": use_tex,\n",
    "        \"use_f16\": use_f16,\n",
    "        \"use_f32\": use_f32,\n",
    "        \"mem_stride\": mem_stride,\n",
    "        \"branch_divergence\": branch_divergence,\n",
    "        \"l2_hits\": l2_hits,\n",
    "        \"tensor_cores\": tensor_cores,\n",
    "        \"Perf_Score\": perf_score,\n",
    "    })\n",
    "    return df\n",
    "\n",
    "# ==================================================================================================\n",
    "# 1. TVF-GPU\n",
    "# ==================================================================================================\n",
    "@dataclass\n",
    "class TVFConfigGPU:\n",
    "    reconstruction_error_threshold: float = 0.15\n",
    "    iforest_contamination: float = 0.02\n",
    "\n",
    "class TitanValidationFrameworkGPU:\n",
    "    def __init__(self, reference_data: pd.DataFrame, config: TVFConfigGPU = None):\n",
    "        self.config = config or TVFConfigGPU()\n",
    "        self.reference = reference_data.copy()\n",
    "        self.num_cols = self.reference.select_dtypes(include=[np.number]).columns.tolist()\n",
    "        self.scaler = StandardScaler()\n",
    "        \n",
    "        print(\"   [TVF-GPU] Learning Baseline Structure (Manifold & Anomalies)...\")\n",
    "        if len(self.num_cols) > 0:\n",
    "            X = self.scaler.fit_transform(self.reference[self.num_cols].fillna(0))\n",
    "            self.pca = PCA(n_components=0.95)\n",
    "            self.pca.fit(X)\n",
    "            X_recon = self.pca.inverse_transform(self.pca.transform(X))\n",
    "            self.ref_recon_error = np.mean(np.square(X - X_recon))\n",
    "            self.iforest = IsolationForest(\n",
    "                contamination=self.config.iforest_contamination,\n",
    "                n_jobs=-1,\n",
    "                random_state=42\n",
    "            )\n",
    "            self.iforest.fit(X)\n",
    "        else:\n",
    "            self.pca = None\n",
    "            self.iforest = None\n",
    "            self.ref_recon_error = 0.0\n",
    "\n",
    "    def validate(self, new_data: pd.DataFrame) -> Tuple[bool, pd.DataFrame]:\n",
    "        report_rows = []\n",
    "        missing = set(self.reference.columns) - set(new_data.columns)\n",
    "        if missing:\n",
    "            report_rows.append({\"Module\": \"Integrity\", \"Status\": \"RED\", \"Reason\": f\"Missing: {list(missing)[:3]}\"})\n",
    "        \n",
    "        if self.pca is not None and len(self.num_cols) > 0:\n",
    "            X = self.scaler.transform(new_data[self.num_cols].fillna(0))\n",
    "            X_recon = self.pca.inverse_transform(self.pca.transform(X))\n",
    "            curr_error = np.mean(np.square(X - X_recon))\n",
    "            ratio = curr_error / max(self.ref_recon_error, 1e-9)\n",
    "            if ratio > (1 + self.config.reconstruction_error_threshold):\n",
    "                report_rows.append({\"Module\": \"Structure\", \"Status\": \"RED\", \"Reason\": f\"Manifold Drift (Err: {ratio:.2f}x)\"})\n",
    "            if self.iforest is not None:\n",
    "                preds = self.iforest.predict(X)\n",
    "                rate = (preds == -1).mean()\n",
    "                if rate > self.config.iforest_contamination * 3:\n",
    "                    report_rows.append({\"Module\": \"Anomalies\", \"Status\": \"RED\", \"Reason\": f\"High Anomaly Rate ({rate:.1%})\"})\n",
    "        \n",
    "        report = pd.DataFrame(report_rows) if report_rows else pd.DataFrame(\n",
    "            [{\"Module\": \"Global\", \"Status\": \"GREEN\", \"Reason\": \"All Systems Nominal\"}]\n",
    "        )\n",
    "        return len(report_rows) == 0, report\n",
    "\n",
    "    def manifold_penalty(self, candidate_df: pd.DataFrame) -> float:\n",
    "        if self.pca is None or len(self.num_cols) == 0:\n",
    "            return 0.0\n",
    "        df = candidate_df.copy()\n",
    "        for c in self.num_cols:\n",
    "            if c not in df.columns:\n",
    "                df[c] = 0.0\n",
    "        X = self.scaler.transform(df[self.num_cols].fillna(0))\n",
    "        X_recon = self.pca.inverse_transform(self.pca.transform(X))\n",
    "        recon_ratio = np.mean((X - X_recon) ** 2) / max(self.ref_recon_error, 1e-9)\n",
    "        return float(max(0.0, recon_ratio - 1.2))\n",
    "\n",
    "# ==================================================================================================\n",
    "# 2. UDE-GPU\n",
    "# ==================================================================================================\n",
    "class UnifiedDiscoveryEngineGPU:\n",
    "    def __init__(self, df, target_col):\n",
    "        self.raw_df = df.copy()\n",
    "        self.target = target_col\n",
    "        self.features = [c for c in df.columns if c != target_col]\n",
    "        print(f\"üîç UDE-GPU ONLINE. Target: '{self.target}'\")\n",
    "\n",
    "    def scan_physics(self):\n",
    "        print(\"\\n>> [UDE-GPU] SCANNING SYNTHETIC KERNEL PHYSICS...\")\n",
    "        X, y = self.raw_df[self.features], self.raw_df[self.target]\n",
    "        model = xgb.XGBRegressor(n_estimators=200, max_depth=6, n_jobs=-1, random_state=42)\n",
    "        model.fit(X, y)\n",
    "        imp = pd.Series(model.feature_importances_, index=self.features).sort_values(ascending=False)\n",
    "        print(f\"   Baseline R¬≤: {model.score(X, y):.4f}\")\n",
    "        self.model = model\n",
    "        return imp\n",
    "\n",
    "    def detect_redundancy(self, top_features, threshold=0.90):\n",
    "        print(\"\\n>> [UDE-GPU] PURGING REDUNDANT DIMENSIONS...\")\n",
    "        survivors = []\n",
    "        for f in top_features:\n",
    "            is_redundant = False\n",
    "            if survivors:\n",
    "                X_surv = self.raw_df[survivors]\n",
    "                y_feat = self.raw_df[f]\n",
    "                r2 = RandomForestRegressor(\n",
    "                    n_estimators=40, max_depth=6, n_jobs=-1, random_state=42\n",
    "                ).fit(X_surv, y_feat).score(X_surv, y_feat)\n",
    "                if r2 > threshold:\n",
    "                    print(f\"   ‚öîÔ∏è Killed '{f}' (Redundant with Survivors, R¬≤={r2:.2f})\")\n",
    "                    is_redundant = True\n",
    "            if not is_redundant:\n",
    "                survivors.append(f)\n",
    "        return survivors\n",
    "\n",
    "# ==================================================================================================\n",
    "# 3. UAV-GPU\n",
    "# ==================================================================================================\n",
    "class UniversalAttributionValidatorGPU:\n",
    "    def __init__(self, X_df, y_series):\n",
    "        self.X_vals = X_df.values.astype(np.float32)\n",
    "        self.y_vals = y_series.values.astype(np.float32)\n",
    "        self.cols = X_df.columns.tolist()\n",
    "        self.X_t = torch.from_numpy(self.X_vals).to(DEVICE)\n",
    "        self.y_t = torch.from_numpy(self.y_vals).reshape(-1, 1).to(DEVICE)\n",
    "        self._train_proxy()\n",
    "\n",
    "    def _train_proxy(self):\n",
    "        print(f\"\\n‚öñÔ∏è [UAV-GPU] TRAINING DIFFERENTIABLE SURROGATE...\")\n",
    "        d_in = self.X_t.shape[1]\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(d_in, 128), nn.SiLU(), nn.Dropout(0.1),\n",
    "            nn.Linear(128, 64), nn.SiLU(), nn.Linear(64, 1)\n",
    "        ).to(DEVICE)\n",
    "        opt = torch.optim.Adam(self.model.parameters(), lr=0.002)\n",
    "        loss_fn = nn.MSELoss()\n",
    "        for _ in tqdm(range(400), desc=\"   Training GPU Surrogate\", leave=False):\n",
    "            opt.zero_grad()\n",
    "            pred = self.model(self.X_t + torch.randn_like(self.X_t)*0.01)\n",
    "            loss = loss_fn(pred, self.y_t)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "\n",
    "    def compute_integrated_gradients(self, n_steps=50):\n",
    "        print(\"   [UAV-GPU] Calculating Gradient Flows (Sensitivity)...\")\n",
    "        baseline = torch.mean(self.X_t, dim=0, keepdim=True)\n",
    "        batch = self.X_t[:min(5000, self.X_t.shape[0])]\n",
    "        grads_acc = torch.zeros_like(batch)\n",
    "        for alpha in np.linspace(0, 1, n_steps):\n",
    "            x_step = baseline + alpha * (batch - baseline)\n",
    "            x_step.requires_grad = True\n",
    "            out = self.model(x_step).sum()\n",
    "            out.backward()\n",
    "            grads_acc += x_step.grad\n",
    "        avg_grads = grads_acc / n_steps\n",
    "        attr = (batch - baseline) * avg_grads\n",
    "        return pd.Series(attr.detach().cpu().numpy().mean(axis=0), index=self.cols).sort_values(ascending=False)\n",
    "\n",
    "# ==================================================================================================\n",
    "# 4. UIF-GPU\n",
    "# ==================================================================================================\n",
    "class PlatinumCausalEngineGPU:\n",
    "    def __init__(self, df, graph_edges):\n",
    "        self.df = df\n",
    "        self.G = nx.DiGraph(graph_edges)\n",
    "        self.models = {}\n",
    "        self._fit_mechanisms()\n",
    "\n",
    "    def _fit_mechanisms(self):\n",
    "        print(\"\\n‚öôÔ∏è [UIF-GPU] FITTING KERNEL CAUSAL MECHANISMS...\")\n",
    "        for node in self.G.nodes():\n",
    "            parents = list(self.G.predecessors(node))\n",
    "            if parents:\n",
    "                self.models[node] = xgb.XGBRegressor(\n",
    "                    n_estimators=80, max_depth=4, n_jobs=-1\n",
    "                ).fit(self.df[parents], self.df[node])\n",
    "\n",
    "    def simulate(self, intervention: dict, target: str):\n",
    "        sim_df = self.df.sample(n=min(5000, len(self.df)), replace=True).copy()\n",
    "        for node, val in intervention.items():\n",
    "            sim_df[node] = val\n",
    "        sorted_nodes = list(nx.topological_sort(self.G))\n",
    "        for node in sorted_nodes:\n",
    "            if node in intervention: continue\n",
    "            parents = list(self.G.predecessors(node))\n",
    "            if parents:\n",
    "                sim_df[node] = self.models[node].predict(sim_df[parents])\n",
    "        return sim_df[target].mean(), sim_df[target].std()\n",
    "\n",
    "# ==================================================================================================\n",
    "# 5. UOF-GPU\n",
    "# ==================================================================================================\n",
    "class UnifiedOptimizerGPU:\n",
    "    def __init__(self, objective_func, bounds):\n",
    "        self.func = objective_func\n",
    "        self.bounds = bounds\n",
    "\n",
    "    def optimize_genetic(self, pop_size=60, generations=12):\n",
    "        print(\"üß¨ [UOF-GPU] RUNNING GENETIC EVOLUTION...\")\n",
    "        from scipy.optimize import differential_evolution\n",
    "        \n",
    "        def wrapper(x):\n",
    "            params = {k: v for k, v in zip(self.bounds.keys(), x)}\n",
    "            return -self.func(**params)\n",
    "        \n",
    "        result = differential_evolution(\n",
    "            wrapper,\n",
    "            bounds=list(self.bounds.values()),\n",
    "            maxiter=generations,\n",
    "            popsize=max(6, pop_size // 10),\n",
    "            workers=1\n",
    "        )\n",
    "        return {k: v for k, v in zip(self.bounds.keys(), result.x)}, -result.fun\n",
    "\n",
    "# ==================================================================================================\n",
    "# üöÄ MAIN EXECUTION: GPU SYNTHETIC KERNEL PIPELINE\n",
    "# ==================================================================================================\n",
    "def main_gpu():\n",
    "    print(\"==================================================================================\")\n",
    "    print(\"‚ö° INITIATING SYNTHETIC GPU KERNEL OPTIMIZATION PIPELINE\")\n",
    "    print(\"==================================================================================\")\n",
    "    \n",
    "    # A. DATA GENERATION\n",
    "    print(\">> [SOURCE] Generating Synthetic GPU Kernel Data...\")\n",
    "    gpu_df = generate_gpu_kernel_data(n_samples=20000, seed=42)\n",
    "    print(f\"   ‚úì Synthetic Kernel Data: {gpu_df.shape}\")\n",
    "    \n",
    "    target_col = \"Perf_Score\"\n",
    "    feature_cols = [c for c in gpu_df.columns if c != target_col]\n",
    "    \n",
    "    # Normalize [0,1]\n",
    "    scaler = MinMaxScaler()\n",
    "    gpu_norm = pd.DataFrame(\n",
    "        scaler.fit_transform(gpu_df),\n",
    "        columns=gpu_df.columns\n",
    "    )\n",
    "    \n",
    "    # B. VALIDATION\n",
    "    print(\"\\n[PHASE 1] VALIDATION SCAN (GPU)\")\n",
    "    tvf_gpu = TitanValidationFrameworkGPU(gpu_norm)\n",
    "    passed, report = tvf_gpu.validate(gpu_norm)\n",
    "    print(report)\n",
    "    \n",
    "    # C. DISCOVERY\n",
    "    print(\"\\n[PHASE 2] DISCOVERING GPU KERNEL DRIVERS\")\n",
    "    ude_gpu = UnifiedDiscoveryEngineGPU(gpu_norm, target_col)\n",
    "    importances = ude_gpu.scan_physics()\n",
    "    top_drivers = importances.head(len(feature_cols)).index.tolist()\n",
    "    print(f\"   Top Drivers: {top_drivers}\")\n",
    "    clean_drivers = ude_gpu.detect_redundancy(top_drivers)\n",
    "    print(f\"   Unique Kernel Knobs: {clean_drivers}\")\n",
    "    \n",
    "    # D. ATTRIBUTION\n",
    "    print(\"\\n[PHASE 3] DECODING KERNEL PHYSICS (Attribution)\")\n",
    "    uav_gpu = UniversalAttributionValidatorGPU(gpu_norm[clean_drivers], gpu_norm[target_col])\n",
    "    attr_scores = uav_gpu.compute_integrated_gradients()\n",
    "    print(\"\\nüèÜ KERNEL PARAMETER IMPACT (Sensitivity):\")\n",
    "    print(attr_scores)\n",
    "    \n",
    "    # E. CAUSAL INTERVENTION\n",
    "    print(\"\\n[PHASE 4] SIMULATING INTERVENTIONS\")\n",
    "    edges = []\n",
    "    for src in [\"block_x\", \"block_y\"]:\n",
    "        if src in clean_drivers and \"Perf_Score\" in [target_col]:\n",
    "            edges.append((src, target_col))\n",
    "    for d in clean_drivers:\n",
    "        if d != target_col and (d, target_col) not in edges:\n",
    "            edges.append((d, target_col))\n",
    "    pce_gpu = PlatinumCausalEngineGPU(gpu_norm[clean_drivers + [target_col]], edges)\n",
    "    \n",
    "    top_pos = [k for k in attr_scores.index if attr_scores[k] > 0][:3]\n",
    "    interventions = {k: 1.0 for k in top_pos}\n",
    "    if interventions:\n",
    "        print(f\">> Simulating 'Max-Out' Strategy on {interventions} ...\")\n",
    "        mu, std = pce_gpu.simulate(interventions, target=target_col)\n",
    "        print(f\"   Predicted {target_col} (normalized): {mu:.4f} (¬±{std:.4f})\")\n",
    "    \n",
    "    # F. OPTIMIZATION\n",
    "    print(\"\\n[PHASE 5] GPU KERNEL OPTIMIZATION (Regularized)\")\n",
    "    def objective_gpu(**kwargs):\n",
    "        vec = [kwargs.get(col, 0.5) for col in clean_drivers]\n",
    "        t_vec = torch.tensor([vec], dtype=torch.float32).to(DEVICE)\n",
    "        with torch.no_grad():\n",
    "            base_score = float(uav_gpu.model(t_vec).item())\n",
    "        candidate = {c: 0.5 for c in gpu_norm.columns}\n",
    "        for k, v in zip(clean_drivers, vec):\n",
    "            candidate[k] = v\n",
    "        cand_df = pd.DataFrame([candidate])\n",
    "        penalty = tvf_gpu.manifold_penalty(cand_df)\n",
    "        return base_score - 0.1 * penalty\n",
    "    \n",
    "    bounds_gpu = {k: (0.0, 1.0) for k in clean_drivers}\n",
    "    uof_gpu = UnifiedOptimizerGPU(objective_gpu, bounds_gpu)\n",
    "    best_cfg, best_val = uof_gpu.optimize_genetic(generations=12)\n",
    "    \n",
    "    # G. EXPORT\n",
    "    print(\"\\n[PHASE 6] EXPORTING GPU KERNEL BLUEPRINT\")\n",
    "    best_row_norm = {c: 0.5 for c in gpu_norm.columns}\n",
    "    for k, v in best_cfg.items():\n",
    "        best_row_norm[k] = v\n",
    "    best_row_norm_df = pd.DataFrame([best_row_norm])\n",
    "    best_row_raw_vals = scaler.inverse_transform(best_row_norm_df[gpu_norm.columns])\n",
    "    best_row_raw = pd.Series(best_row_raw_vals[0], index=gpu_norm.columns)\n",
    "    \n",
    "    summary_rows = []\n",
    "    for knob in clean_drivers:\n",
    "        col_idx = list(gpu_norm.columns).index(knob)\n",
    "        col_min = scaler.data_min_[col_idx]\n",
    "        col_max = scaler.data_max_[col_idx]\n",
    "        recommended = best_row_raw[knob]\n",
    "        sensitivity = attr_scores.get(knob, 0.0)\n",
    "        summary_rows.append({\n",
    "            \"Parameter\": knob,\n",
    "            \"Original_Min\": col_min,\n",
    "            \"Original_Max\": col_max,\n",
    "            \"Recommended_Value\": recommended,\n",
    "            \"Sensitivity_Sign\": \"Positive\" if sensitivity > 0 else \"Negative\",\n",
    "            \"Sensitivity_Magnitude\": float(abs(sensitivity))\n",
    "        })\n",
    "    summary_df = pd.DataFrame(summary_rows).sort_values(\"Sensitivity_Magnitude\", ascending=False)\n",
    "    \n",
    "    print(\"\\n==================================================================================\")\n",
    "    print(f\"üèÅ FINAL GPU KERNEL BLUEPRINT (Original Units, target=Perf_Score)\")\n",
    "    print(\"==================================================================================\")\n",
    "    print(f\"üåü MAX ACHIEVABLE Perf_Score (normalized surrogate): {best_val:.4f}\")\n",
    "    print(\"\\nüîß OPTIMAL GPU CONFIG (Top by Sensitivity):\")\n",
    "    print(summary_df.to_string(index=False))\n",
    "    print(\"==================================================================================\")\n",
    "    \n",
    "    gpu_csv_path = \"titan_gpu_control_surface.csv\"\n",
    "    summary_df.to_csv(gpu_csv_path, index=False)\n",
    "    print(f\"üìÑ Saved GPU Control Surface to: {gpu_csv_path}\")\n",
    "    \n",
    "    gpu_spec = {\n",
    "        \"meta\": {\n",
    "            \"version\": \"titan_gpu_synthetic_v1\",\n",
    "            \"description\": \"GPU kernel optimization profile from synthetic kernel-performance simulator.\",\n",
    "            \"target_metric\": \"Perf_Score\",\n",
    "            \"normalized_score\": best_val\n",
    "        },\n",
    "        \"controls\": [],\n",
    "        \"profiles\": {\n",
    "            \"baseline_normalized\": {c: 0.5 for c in gpu_norm.columns},\n",
    "            \"optimized_normalized\": {c: best_cfg.get(c, 0.5) for c in gpu_norm.columns}\n",
    "        }\n",
    "    }\n",
    "    for _, row in summary_df.iterrows():\n",
    "        gpu_spec[\"controls\"].append({\n",
    "            \"name\": row[\"Parameter\"],\n",
    "            \"recommended\": float(row[\"Recommended_Value\"]),\n",
    "            \"min\": float(row[\"Original_Min\"]),\n",
    "            \"max\": float(row[\"Original_Max\"]),\n",
    "            \"impact\": float(row[\"Sensitivity_Magnitude\"])\n",
    "        })\n",
    "    gpu_json_path = \"titan_gpu_profile.json\"\n",
    "    with open(gpu_json_path, \"w\") as f:\n",
    "        json.dump(gpu_spec, f, indent=2)\n",
    "    print(f\"üì¶ Saved GPU JSON Profile to: {gpu_json_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main_gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c3344f2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-22T23:34:21.978425Z",
     "iopub.status.busy": "2026-01-22T23:34:21.978160Z",
     "iopub.status.idle": "2026-01-22T23:34:23.004132Z",
     "shell.execute_reply": "2026-01-22T23:34:23.002837Z"
    },
    "papermill": {
     "duration": 1.03498,
     "end_time": "2026-01-22T23:34:23.006143",
     "exception": false,
     "start_time": "2026-01-22T23:34:21.971163",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SYSTEM ONLINE :: TITAN 0.1nm SINGULARITY CELL 3 :: DEVICE = cuda\n",
      "LOADING 0.1nm DATA ASSEMBLY...\n",
      "Sensitivity map shape: (10000, 7)\n",
      "Ironclad master shape: (4, 3)\n",
      "Gold master shape:     (4, 3)\n",
      "Recipe rows:           (4, 3)\n",
      "Specs meta version:    v17.0\n",
      "PROCESSING UNITS DECLARED:\n",
      " - Majorana_QPU_Core\n",
      " - Floquet_Drive_Unit\n",
      " - Rashba_Field_Controller\n",
      " - Zeeman_Magnet_Unit\n",
      " - Laser_Coherence_Unit\n",
      " - Thermal_Shielding_Unit\n",
      " - Yield_Optimization_Unit\n",
      " - Error_Correction_Unit\n",
      " - Control_Fabric_Unit\n",
      " - Calibration_Unit\n",
      "\n",
      "PHASE 1 :: VALIDATION ‚Äì SENSITIVITY MAP\n",
      "TVF-TC :: Learning baseline manifold...\n",
      "Module Status              Reason\n",
      "Global  GREEN All systems nominal\n",
      "\n",
      "PHASE 2 :: DISCOVERY ‚Äì DRIVERS OF COHERENCE/YIELD\n",
      "\n",
      "Target = Coherence_Yield :: in-sample R2 = 0.9998\n",
      "Freq_THz     0.993414\n",
      "Rashba_eV    0.002148\n",
      "Gap_meV      0.001753\n",
      "Zeeman_T     0.001687\n",
      "Trial_ID     0.000998\n",
      "\n",
      "PHASE 3 :: ATTRIBUTION ‚Äì PARAMETER SENSITIVITY\n",
      "\n",
      "Surrogate gradient sensitivity for target = Coherence_Yield\n",
      "Gap_meV      0.000003\n",
      "Rashba_eV    0.000002\n",
      "Zeeman_T     0.000001\n",
      "Trial_ID     0.000001\n",
      "Freq_THz     0.000001\n",
      "\n",
      "UNIFIED DRIVER FEATURES (merged): ['Freq_THz', 'Gap_meV', 'Rashba_eV', 'Trial_ID', 'Zeeman_T']\n",
      "\n",
      "FINAL OUTPUT :: 0.1nm PROCESSING UNIT BLUEPRINT\n",
      "- Saved JSON to titan_0_1nm_processing_units.json\n",
      "- Processing Units:\n",
      "  * Majorana_QPU_Core: 1 controls\n",
      "  * Floquet_Drive_Unit: 1 controls\n",
      "  * Rashba_Field_Controller: 1 controls\n",
      "  * Zeeman_Magnet_Unit: 1 controls\n",
      "  * Laser_Coherence_Unit: 1 controls\n",
      "  * Thermal_Shielding_Unit: 1 controls\n",
      "  * Yield_Optimization_Unit: 1 controls\n",
      "  * Error_Correction_Unit: 1 controls\n",
      "  * Control_Fabric_Unit: 1 controls\n",
      "  * Calibration_Unit: 1 controls\n"
     ]
    }
   ],
   "source": [
    "# TITAN 0.1nm SINGULARITY ‚Äì ALL PROCESSING UNITS BLUEPRINT (Cell 3)\n",
    "\n",
    "import os\n",
    "import json\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import xgboost as xgb\n",
    "import networkx as nx\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, List, Tuple\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.ensemble import IsolationForest, RandomForestRegressor\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"SYSTEM ONLINE :: TITAN 0.1nm SINGULARITY CELL 3 :: DEVICE = {DEVICE}\")\n",
    "\n",
    "# --------------------------------------------------------------------\n",
    "# A. DATA INGESTION FROM KAGGLE INPUT\n",
    "# --------------------------------------------------------------------\n",
    "BASE = \"/kaggle/input/0-1nm-chip-data\"\n",
    "\n",
    "sens_path   = os.path.join(BASE, \"Titan_Sensitivity_Map.csv\")\n",
    "iron_path   = os.path.join(BASE, \"Titan_Ironclad_Master.csv\")\n",
    "gold_path   = os.path.join(BASE, \"Titan_Gold_Master.csv\")\n",
    "specs_path  = os.path.join(BASE, \"Titan_Final_Specs.json\")\n",
    "exec_path   = os.path.join(BASE, \"Titan_Executive_Summary.txt\")\n",
    "recipe_path = os.path.join(BASE, \"0.1nm_Singularity_Recipe.csv\")\n",
    "\n",
    "print(\"LOADING 0.1nm DATA ASSEMBLY...\")\n",
    "sens_df   = pd.read_csv(sens_path)\n",
    "iron_df   = pd.read_csv(iron_path)\n",
    "gold_df   = pd.read_csv(gold_path)\n",
    "specs     = json.load(open(specs_path, \"r\"))\n",
    "exec_txt  = open(exec_path, \"r\", encoding=\"utf-8\").read()\n",
    "recipe_df = pd.read_csv(recipe_path)\n",
    "\n",
    "print(f\"Sensitivity map shape: {sens_df.shape}\")\n",
    "print(f\"Ironclad master shape: {iron_df.shape}\")\n",
    "print(f\"Gold master shape:     {gold_df.shape}\")\n",
    "print(f\"Recipe rows:           {recipe_df.shape}\")\n",
    "print(f\"Specs meta version:    {specs.get('meta', {}).get('version', 'NA')}\")\n",
    "\n",
    "# --------------------------------------------------------------------\n",
    "# B. PROCESSING UNIT TAXONOMY FOR 0.1 nm CHIP\n",
    "# --------------------------------------------------------------------\n",
    "# Inspired by CPU OS ‚Äúcontrol surface‚Äù + GPU kernel ‚Äúknobs‚Äù,\n",
    "# but now for topological 0.1 nm time‚Äëcrystal qubits.\n",
    "\n",
    "PROCESSING_UNIT_TYPES = [\n",
    "    \"Majorana_QPU_Core\",          # Primary topological qubit array\n",
    "    \"Floquet_Drive_Unit\",         # Periodic drive/time‚Äëcrystal engine\n",
    "    \"Rashba_Field_Controller\",    # Spin‚Äëorbit coupling synthesis\n",
    "    \"Zeeman_Magnet_Unit\",         # Static / slowly varying Bz control\n",
    "    \"Laser_Coherence_Unit\",       # Femtosecond THz laser timing unit\n",
    "    \"Thermal_Shielding_Unit\",     # 10 mK fridge + shielding coordination\n",
    "    \"Yield_Optimization_Unit\",    # Manufacturability / Monte Carlo aware\n",
    "    \"Error_Correction_Unit\",      # Logical code & syndrome pipeline\n",
    "    \"Control_Fabric_Unit\",        # Routing, multiplexing, fan‚Äëout\n",
    "    \"Calibration_Unit\"            # In‚Äësitu calibration & retune engine\n",
    "]\n",
    "\n",
    "print(\"PROCESSING UNITS DECLARED:\")\n",
    "for pu in PROCESSING_UNIT_TYPES:\n",
    "    print(\" -\", pu)\n",
    "\n",
    "# --------------------------------------------------------------------\n",
    "# C. TVF ‚Äì LIGHTWEIGHT VALIDATION FOR SENSITIVITY MAP\n",
    "# --------------------------------------------------------------------\n",
    "@dataclass\n",
    "class TVFConfigTC:\n",
    "    reconstruction_error_threshold: float = 0.15\n",
    "    iforest_contamination: float = 0.02\n",
    "\n",
    "class TitanValidationFrameworkTC:\n",
    "    def __init__(self, reference: pd.DataFrame, config: TVFConfigTC = None):\n",
    "        self.config = config or TVFConfigTC()\n",
    "        self.reference = reference.copy()\n",
    "        self.num_cols = self.reference.select_dtypes(include=np.number).columns.tolist()\n",
    "        self.scaler = StandardScaler()\n",
    "        print(\"TVF-TC :: Learning baseline manifold...\")\n",
    "        if len(self.num_cols) > 0:\n",
    "            X = self.scaler.fit_transform(self.reference[self.num_cols].fillna(0))\n",
    "            self.pca = PCA(n_components=0.95)\n",
    "            self.pca.fit(X)\n",
    "            X_recon = self.pca.inverse_transform(self.pca.transform(X))\n",
    "            self.ref_error = np.mean((X - X_recon) ** 2)\n",
    "            self.iforest = IsolationForest(\n",
    "                contamination=self.config.iforest_contamination,\n",
    "                n_jobs=-1,\n",
    "                random_state=42\n",
    "            ).fit(X)\n",
    "        else:\n",
    "            self.pca = None\n",
    "            self.iforest = None\n",
    "            self.ref_error = 0.0\n",
    "\n",
    "    def validate(self, new_df: pd.DataFrame) -> Tuple[bool, pd.DataFrame]:\n",
    "        rows = []\n",
    "        missing = set(self.reference.columns) - set(new_df.columns)\n",
    "        if missing:\n",
    "            rows.append(dict(Module=\"Integrity\",\n",
    "                            Status=\"RED\",\n",
    "                            Reason=f\"Missing columns: {list(missing)[:5]}\"))\n",
    "        if self.pca is not None and len(self.num_cols) > 0:\n",
    "            X = self.scaler.transform(new_df[self.num_cols].fillna(0))\n",
    "            X_recon = self.pca.inverse_transform(self.pca.transform(X))\n",
    "            err = np.mean((X - X_recon) ** 2)\n",
    "            ratio = err / max(self.ref_error, 1e-9)\n",
    "            if ratio > 1 + self.config.reconstruction_error_threshold:\n",
    "                rows.append(dict(Module=\"Structure\",\n",
    "                                 Status=\"RED\",\n",
    "                                 Reason=f\"Manifold drift err ratio={ratio:.2f}\"))\n",
    "        if self.iforest is not None:\n",
    "            X = self.scaler.transform(new_df[self.num_cols].fillna(0))\n",
    "            preds = self.iforest.predict(X)\n",
    "            rate = (preds == -1).mean()\n",
    "            if rate > self.config.iforest_contamination * 3:\n",
    "                rows.append(dict(Module=\"Anomalies\",\n",
    "                                 Status=\"RED\",\n",
    "                                 Reason=f\"High anomaly rate={rate:.3f}\"))\n",
    "        if not rows:\n",
    "            rows.append(dict(Module=\"Global\",\n",
    "                             Status=\"GREEN\",\n",
    "                             Reason=\"All systems nominal\"))\n",
    "        return (len(rows) == 1 and rows[0][\"Status\"] == \"GREEN\",\n",
    "                pd.DataFrame(rows))\n",
    "\n",
    "print(\"\\nPHASE 1 :: VALIDATION ‚Äì SENSITIVITY MAP\")\n",
    "# Reference = full sensitivity map; we validate on same to get envelope\n",
    "tvf_tc = TitanValidationFrameworkTC(sens_df)\n",
    "passed_tc, report_tc = tvf_tc.validate(sens_df)\n",
    "print(report_tc.to_string(index=False))\n",
    "\n",
    "# --------------------------------------------------------------------\n",
    "# D. DISCOVERY ‚Äì WHAT DRIVES COHERENCE / YIELD\n",
    "# --------------------------------------------------------------------\n",
    "# Assume columns like: Rashba (eV), Zeeman (T), Gap (meV), Freq (THz),\n",
    "# Coherence (0..1), Yield (0..1), Status (PASS/FAIL)\n",
    "# We will:\n",
    "#   - define numerical features\n",
    "#   - targets: \"Coherence\" and \"Yield\" (if present)\n",
    "#   - feature importance via XGBoost\n",
    "\n",
    "sens_num = sens_df.select_dtypes(include=np.number).copy()\n",
    "# Normalize quickly for stability\n",
    "mm = MinMaxScaler()\n",
    "sens_norm = pd.DataFrame(mm.fit_transform(sens_num), columns=sens_num.columns)\n",
    "\n",
    "targets = []\n",
    "for t in [\"Coherence\", \"Yield\"]:\n",
    "    if t in sens_norm.columns:\n",
    "        targets.append(t)\n",
    "\n",
    "if len(targets) == 0:\n",
    "    # Fallback: if not explicitly named, assume last numeric col is coherence proxy\n",
    "    targets.append(sens_norm.columns[-1])\n",
    "\n",
    "print(\"\\nPHASE 2 :: DISCOVERY ‚Äì DRIVERS OF COHERENCE/YIELD\")\n",
    "feature_importances: Dict[str, Dict[str, float]] = {}\n",
    "\n",
    "for tgt in targets:\n",
    "    X = sens_norm.drop(columns=[tgt])\n",
    "    y = sens_norm[tgt]\n",
    "    model = xgb.XGBRegressor(\n",
    "        n_estimators=200,\n",
    "        max_depth=5,\n",
    "        learning_rate=0.05,\n",
    "        subsample=0.9,\n",
    "        colsample_bytree=0.9,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    model.fit(X, y)\n",
    "    r2 = model.score(X, y)\n",
    "    imp = pd.Series(model.feature_importances_, index=X.columns).sort_values(ascending=False)\n",
    "    feature_importances[tgt] = imp.to_dict()\n",
    "    print(f\"\\nTarget = {tgt} :: in-sample R2 = {r2:.4f}\")\n",
    "    print(imp.head(10).to_string())\n",
    "\n",
    "# --------------------------------------------------------------------\n",
    "# E. ATTRIBUTION ‚Äì SIMPLE NN SURROGATE + GRADIENTS\n",
    "# --------------------------------------------------------------------\n",
    "class SurrogateNN(nn.Module):\n",
    "    def __init__(self, d_in: int):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(d_in, 64),\n",
    "            nn.SiLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(32, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "def train_surrogate(X: np.ndarray, y: np.ndarray, epochs: int = 300) -> SurrogateNN:\n",
    "    X_t = torch.tensor(X, dtype=torch.float32, device=DEVICE)\n",
    "    y_t = torch.tensor(y.reshape(-1, 1), dtype=torch.float32, device=DEVICE)\n",
    "    model = SurrogateNN(X_t.shape[1]).to(DEVICE)\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=0.002, weight_decay=1e-4)\n",
    "    loss_fn = nn.MSELoss()\n",
    "    for _ in range(epochs):\n",
    "        opt.zero_grad()\n",
    "        pred = model(X_t)\n",
    "        loss = loss_fn(pred, y_t)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "    return model\n",
    "\n",
    "def compute_grad_sensitivity(model: SurrogateNN, X: np.ndarray, cols: List[str]) -> pd.Series:\n",
    "    X_t = torch.tensor(X, dtype=torch.float32, device=DEVICE, requires_grad=True)\n",
    "    out = model(X_t).mean()\n",
    "    out.backward()\n",
    "    grads = X_t.grad.detach().cpu().numpy()\n",
    "    sens = np.mean(np.abs(grads), axis=0)\n",
    "    return pd.Series(sens, index=cols).sort_values(ascending=False)\n",
    "\n",
    "print(\"\\nPHASE 3 :: ATTRIBUTION ‚Äì PARAMETER SENSITIVITY\")\n",
    "\n",
    "surrogate_sensitivity: Dict[str, Dict[str, float]] = {}\n",
    "for tgt in targets:\n",
    "    X = sens_norm.drop(columns=[tgt])\n",
    "    y = sens_norm[tgt].values\n",
    "    model = train_surrogate(X.values, y, epochs=200)\n",
    "    sens_scores = compute_grad_sensitivity(model, X.values, X.columns.tolist())\n",
    "    surrogate_sensitivity[tgt] = sens_scores.to_dict()\n",
    "    print(f\"\\nSurrogate gradient sensitivity for target = {tgt}\")\n",
    "    print(sens_scores.head(10).to_string())\n",
    "\n",
    "# --------------------------------------------------------------------\n",
    "# F. PROCESSING UNIT PARAMETER SURFACES\n",
    "# --------------------------------------------------------------------\n",
    "# We now map: features + sensitivities + gold/iron recipes\n",
    "# into per‚ÄëProcessingUnit normalized control surfaces.\n",
    "\n",
    "# Extract canonical recipe values (Gold) as ‚Äúbest known‚Äù\n",
    "gold_map = {}\n",
    "if \"Parameter\" in gold_df.columns and \"Setpoint\" in gold_df.columns:\n",
    "    for _, row in gold_df.iterrows():\n",
    "        name = str(row[\"Parameter\"]).strip()\n",
    "        gold_map[name.upper()] = float(row[\"Setpoint\"])\n",
    "else:\n",
    "    # Fallback to generic 2‚Äëcol layout\n",
    "    for _, row in gold_df.iterrows():\n",
    "        name = str(row.iloc[0]).strip()\n",
    "        val = float(row.iloc[1])\n",
    "        gold_map[name.upper()] = val\n",
    "\n",
    "# Extract nominal recipe row (0.1nm_Singularity_Recipe)\n",
    "recipe_map = {}\n",
    "if \"Param\" in recipe_df.columns and \"Val\" in recipe_df.columns:\n",
    "    for _, row in recipe_df.iterrows():\n",
    "        recipe_map[str(row[\"Param\"]).upper()] = float(row[\"Val\"])\n",
    "else:\n",
    "    # Fallback: first two columns\n",
    "    for _, row in recipe_df.iterrows():\n",
    "        recipe_map[str(row.iloc[0]).upper()] = float(row.iloc[1])\n",
    "\n",
    "def get_nominal(param_key: str, default: float = 0.0) -> float:\n",
    "    k = param_key.upper()\n",
    "    if k in gold_map:\n",
    "        return gold_map[k]\n",
    "    if k in recipe_map:\n",
    "        return recipe_map[k]\n",
    "    return default\n",
    "\n",
    "# Helper: min/max from sensitivity map (denormalized)\n",
    "sens_min = sens_num.min()\n",
    "sens_max = sens_num.max()\n",
    "\n",
    "def original_minmax(col: str) -> Tuple[float, float]:\n",
    "    if col in sens_min.index:\n",
    "        return float(sens_min[col]), float(sens_max[col])\n",
    "    return 0.0, 1.0\n",
    "\n",
    "# Map features to ‚Äúwhich ProcessingUnit owns them‚Äù\n",
    "def assign_unit_for_feature(fname: str) -> str:\n",
    "    n = fname.lower()\n",
    "    if \"rashba\" in n:\n",
    "        return \"Rashba_Field_Controller\"\n",
    "    if \"zeeman\" in n or \"bz\" in n:\n",
    "        return \"Zeeman_Magnet_Unit\"\n",
    "    if \"gap\" in n or \"majorana\" in n:\n",
    "        return \"Majorana_QPU_Core\"\n",
    "    if \"freq\" in n or \"laser\" in n or \"thz\" in n:\n",
    "        return \"Laser_Coherence_Unit\"\n",
    "    if \"temp\" in n or \"thermal\" in n or \"mK\" in n:\n",
    "        return \"Thermal_Shielding_Unit\"\n",
    "    if \"yield\" in n:\n",
    "        return \"Yield_Optimization_Unit\"\n",
    "    if \"coherence\" in n:\n",
    "        return \"Majorana_QPU_Core\"\n",
    "    # default catch‚Äëall\n",
    "    return \"Control_Fabric_Unit\"\n",
    "\n",
    "# Build unified set of driver features from importance + sensitivity\n",
    "driver_features = set()\n",
    "for tgt in targets:\n",
    "    imp = feature_importances[tgt]\n",
    "    sens = surrogate_sensitivity[tgt]\n",
    "    # Take top 15 from each\n",
    "    top_imp = sorted(imp.items(), key=lambda x: x[1], reverse=True)[:15]\n",
    "    top_sens = sorted(sens.items(), key=lambda x: x[1], reverse=True)[:15]\n",
    "    for k, _ in top_imp + top_sens:\n",
    "        driver_features.add(k)\n",
    "\n",
    "driver_features = sorted(list(driver_features))\n",
    "print(\"\\nUNIFIED DRIVER FEATURES (merged):\", driver_features)\n",
    "\n",
    "# --------------------------------------------------------------------\n",
    "# G. BUILD JSON BLUEPRINT ‚Äì ALL PROCESSING UNITS\n",
    "# --------------------------------------------------------------------\n",
    "# Structure:\n",
    "# {\n",
    "#   \"meta\": {...},\n",
    "#   \"processing_units\": [\n",
    "#       {\n",
    "#         \"name\": \"...\",\n",
    "#         \"role\": \"...\",\n",
    "#         \"controls\": [\n",
    "#            { \"parameter\": \"...\", \"owner_feature\": \"...\", \"min\":..., \"max\":..., \"nominal\":..., \"importance\":..., \"sensitivity\":... }\n",
    "#         ]\n",
    "#       }, ...\n",
    "#   ]\n",
    "# }\n",
    "\n",
    "PU_ROLES = {\n",
    "    \"Majorana_QPU_Core\": \"Topological qubit array and Majorana gap stabilization.\",\n",
    "    \"Floquet_Drive_Unit\": \"Implements periodic drive for time-crystal Floquet engineering.\",\n",
    "    \"Rashba_Field_Controller\": \"Controls spin-orbit coupling strength (Rashba).\",\n",
    "    \"Zeeman_Magnet_Unit\": \"Controls static and slow-varying Zeeman Bz field.\",\n",
    "    \"Laser_Coherence_Unit\": \"Controls THz laser frequency and timing coherence.\",\n",
    "    \"Thermal_Shielding_Unit\": \"Coordinates fridge temperature and shielding at 10mK.\",\n",
    "    \"Yield_Optimization_Unit\": \"Maximizes fabrication yield under jitter and noise.\",\n",
    "    \"Error_Correction_Unit\": \"Logical error correction and syndrome routing.\",\n",
    "    \"Control_Fabric_Unit\": \"Routing, multiplexing, fanout, and digital control fabric.\",\n",
    "    \"Calibration_Unit\": \"Automated calibration and re-tuning of all analog parameters.\"\n",
    "}\n",
    "\n",
    "blueprint = {\n",
    "    \"meta\": {\n",
    "        \"version\": \"titan-singularity-cell3-v1\",\n",
    "        \"description\": \"0.1nm topological time-crystal processing-unit taxonomy and control surfaces.\",\n",
    "        \"source_specs_version\": specs.get(\"meta\", {}).get(\"version\", \"unknown\"),\n",
    "        \"targets\": targets,\n",
    "    },\n",
    "    \"processing_units\": []\n",
    "}\n",
    "\n",
    "# Initialize units\n",
    "unit_map: Dict[str, Dict] = {}\n",
    "for pu in PROCESSING_UNIT_TYPES:\n",
    "    unit_map[pu] = {\n",
    "        \"name\": pu,\n",
    "        \"role\": PU_ROLES.get(pu, \"\"),\n",
    "        \"controls\": []\n",
    "    }\n",
    "\n",
    "# Pack controls per driver feature\n",
    "for feat in driver_features:\n",
    "    owner = assign_unit_for_feature(feat)\n",
    "    min_v, max_v = original_minmax(feat)\n",
    "    nominal = get_nominal(feat, default=(min_v + max_v) / 2.0)\n",
    "\n",
    "    # Aggregate importance/sensitivity across all targets\n",
    "    imp_vals = []\n",
    "    sens_vals = []\n",
    "    for tgt in targets:\n",
    "        imp_vals.append(feature_importances.get(tgt, {}).get(feat, 0.0))\n",
    "        sens_vals.append(surrogate_sensitivity.get(tgt, {}).get(feat, 0.0))\n",
    "\n",
    "    importance = float(np.mean(imp_vals)) if imp_vals else 0.0\n",
    "    sensitivity = float(np.mean(sens_vals)) if sens_vals else 0.0\n",
    "\n",
    "    control = {\n",
    "        \"parameter\": feat,\n",
    "        \"owner_feature\": feat,\n",
    "        \"min\": float(min_v),\n",
    "        \"max\": float(max_v),\n",
    "        \"nominal\": float(nominal),\n",
    "        \"importance_score\": importance,\n",
    "        \"sensitivity_score\": sensitivity\n",
    "    }\n",
    "    unit_map[owner][\"controls\"].append(control)\n",
    "\n",
    "# Simple placeholder controls for units that may not receive features\n",
    "for pu in PROCESSING_UNIT_TYPES:\n",
    "    if not unit_map[pu][\"controls\"]:\n",
    "        unit_map[pu][\"controls\"].append({\n",
    "            \"parameter\": \"virtual_control_gain\",\n",
    "            \"owner_feature\": \"none\",\n",
    "            \"min\": 0.0,\n",
    "            \"max\": 1.0,\n",
    "            \"nominal\": 0.5,\n",
    "            \"importance_score\": 0.0,\n",
    "            \"sensitivity_score\": 0.0\n",
    "        })\n",
    "\n",
    "blueprint[\"processing_units\"] = list(unit_map.values())\n",
    "\n",
    "# --------------------------------------------------------------------\n",
    "# H. EXPORT JSON FOR CELL 4 (DEVELOPER-SPECIFIC DETAILS)\n",
    "# --------------------------------------------------------------------\n",
    "out_json_path = \"titan_0_1nm_processing_units.json\"\n",
    "with open(out_json_path, \"w\") as f:\n",
    "    json.dump(blueprint, f, indent=2)\n",
    "\n",
    "print(\"\\nFINAL OUTPUT :: 0.1nm PROCESSING UNIT BLUEPRINT\")\n",
    "print(f\"- Saved JSON to {out_json_path}\")\n",
    "print(\"- Processing Units:\")\n",
    "for pu in PROCESSING_UNIT_TYPES:\n",
    "    n_ctrl = len(unit_map[pu][\"controls\"])\n",
    "    print(f\"  * {pu}: {n_ctrl} controls\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ecfeea22",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-22T23:34:23.020970Z",
     "iopub.status.busy": "2026-01-22T23:34:23.020633Z",
     "iopub.status.idle": "2026-01-22T23:34:23.058487Z",
     "shell.execute_reply": "2026-01-22T23:34:23.057466Z"
    },
    "papermill": {
     "duration": 0.047478,
     "end_time": "2026-01-22T23:34:23.060169",
     "exception": false,
     "start_time": "2026-01-22T23:34:23.012691",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SYSTEM ONLINE :: TITAN 0.1nm SINGULARITY CELL 4\n",
      "Loaded base blueprint version: titan-singularity-cell3-v1\n",
      "Specs version: v17.0 target: 0.1nm Time Crystal\n",
      "EXPORT COMPLETE:\n",
      " - titan_0_1nm_system_modes.json\n",
      " - titan_0_1nm_full_spec.json\n",
      "   * Majorana_QPU_Core: 2 modes\n",
      "   * Floquet_Drive_Unit: 2 modes\n",
      "   * Rashba_Field_Controller: 1 modes\n",
      "   * Zeeman_Magnet_Unit: 2 modes\n",
      "   * Laser_Coherence_Unit: 1 modes\n",
      "   * Thermal_Shielding_Unit: 1 modes\n",
      "   * Yield_Optimization_Unit: 1 modes\n",
      "   * Error_Correction_Unit: 1 modes\n",
      "   * Control_Fabric_Unit: 1 modes\n",
      "   * Calibration_Unit: 1 modes\n"
     ]
    }
   ],
   "source": [
    "# TITAN 0.1nm SINGULARITY ‚Äì CELL 4\n",
    "# Developer-Ready Per-Unit Modes & Parameters\n",
    "\n",
    "import json\n",
    "import os\n",
    "from copy import deepcopy\n",
    "\n",
    "BASE_BLUEPRINT_PATH = \"titan_0_1nm_processing_units.json\"\n",
    "\n",
    "print(\"SYSTEM ONLINE :: TITAN 0.1nm SINGULARITY CELL 4\")\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# A. LOAD CELL 3 BLUEPRINT + FINAL SPECS\n",
    "# -------------------------------------------------------------\n",
    "with open(BASE_BLUEPRINT_PATH, \"r\") as f:\n",
    "    base_blueprint = json.load(f)\n",
    "\n",
    "# If running in Kaggle, also load Titan_Final_Specs.json for exact recipe\n",
    "specs_path = \"/kaggle/input/0-1nm-chip-data/Titan_Final_Specs.json\"\n",
    "specs = json.load(open(specs_path, \"r\"))\n",
    "\n",
    "recipe = specs.get(\"recipe\", {})\n",
    "perf   = specs.get(\"performance\", {})\n",
    "meta   = specs.get(\"meta\", {})\n",
    "\n",
    "print(\"Loaded base blueprint version:\", base_blueprint[\"meta\"][\"version\"])\n",
    "print(\"Specs version:\", meta.get(\"version\"), \"target:\", meta.get(\"target\"))\n",
    "\n",
    "# Convenience helpers\n",
    "def get_unit(name: str):\n",
    "    for u in base_blueprint[\"processing_units\"]:\n",
    "        if u[\"name\"] == name:\n",
    "            return u\n",
    "    return None\n",
    "\n",
    "def nominal_from_recipe(key: str, fallback: float):\n",
    "    # Map from blueprint parameter naming to recipe keys\n",
    "    key_upper = key.upper()\n",
    "    if \"RASHBA\" in key_upper:\n",
    "        return float(recipe.get(\"RASHBA_COUPLING\", fallback))\n",
    "    if \"ZEEMAN\" in key_upper:\n",
    "        return float(recipe.get(\"ZEEMAN_FIELD\", fallback))\n",
    "    if \"GAP\" in key_upper or \"MAJORANA\" in key_upper:\n",
    "        return float(recipe.get(\"MAJORANA_GAP\", fallback))\n",
    "    if \"FREQ\" in key_upper or \"THZ\" in key_upper:\n",
    "        return float(recipe.get(\"LASER_FREQ_THz\", fallback))\n",
    "    return float(fallback)\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# B. DEFINE STANDARD MODE SCHEMA\n",
    "# -------------------------------------------------------------\n",
    "# Each Processing Unit will have:\n",
    "# {\n",
    "#   \"name\": \"...\",\n",
    "#   \"modes\": [\n",
    "#       {\n",
    "#          \"mode_name\": \"...\",\n",
    "#          \"description\": \"...\",\n",
    "#          \"target_profile\": { ... },\n",
    "#          \"controls\": [ ... ]\n",
    "#       },\n",
    "#       ...\n",
    "#   ]\n",
    "# }\n",
    "\n",
    "system_modes = {\n",
    "    \"meta\": {\n",
    "        \"version\": \"titan-singularity-cell4-v1\",\n",
    "        \"description\": \"Per-Processing-Unit operating modes and parameter envelopes for 0.1nm Time Crystal.\",\n",
    "        \"derived_from\": base_blueprint[\"meta\"][\"version\"],\n",
    "        \"specs_version\": meta.get(\"version\", \"unknown\"),\n",
    "        \"target\": meta.get(\"target\", \"0.1nm Time Crystal\"),\n",
    "        \"global_performance\": perf,\n",
    "    },\n",
    "    \"units\": []\n",
    "}\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# C. MODE GENERATORS PER PROCESSING UNIT\n",
    "# -------------------------------------------------------------\n",
    "def make_majorana_modes(unit):\n",
    "    # Gap_meV already present as control\n",
    "    gap_ctrl = unit[\"controls\"][0]\n",
    "    base_nom = nominal_from_recipe(\"MAJORANA_GAP\", gap_ctrl[\"nominal\"])\n",
    "    return [\n",
    "        {\n",
    "            \"mode_name\": \"Idle_Protected\",\n",
    "            \"description\": \"QPU parked in topological phase with maximal gap and coherence.\",\n",
    "            \"target_profile\": {\n",
    "                \"coherence_target\": 0.9999,\n",
    "                \"gap_target_meV\": base_nom,\n",
    "                \"allowed_gap_variation_meV\": 0.25 * (gap_ctrl[\"max\"] - gap_ctrl[\"min\"]),\n",
    "                \"allowed_error_rate\": 1e-6\n",
    "            },\n",
    "            \"controls\": [\n",
    "                {\n",
    "                    \"parameter\": gap_ctrl[\"parameter\"],\n",
    "                    \"nominal\": base_nom,\n",
    "                    \"range\": [gap_ctrl[\"min\"], gap_ctrl[\"max\"]],\n",
    "                    \"tuning_policy\": \"keep within 1œÉ of nominal during Idle_Protected\",\n",
    "                    \"priority\": \"HIGH\"\n",
    "                }\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"mode_name\": \"Gate_Operation\",\n",
    "            \"description\": \"QPU in active braiding / gate execution; allows small transient gap modulation.\",\n",
    "            \"target_profile\": {\n",
    "                \"coherence_target\": 0.999,\n",
    "                \"gap_target_meV\": base_nom,\n",
    "                \"allowed_gap_variation_meV\": 0.5 * (gap_ctrl[\"max\"] - gap_ctrl[\"min\"]),\n",
    "                \"allowed_error_rate\": 5e-5\n",
    "            },\n",
    "            \"controls\": [\n",
    "                {\n",
    "                    \"parameter\": gap_ctrl[\"parameter\"],\n",
    "                    \"nominal\": base_nom,\n",
    "                    \"range\": [gap_ctrl[\"min\"], gap_ctrl[\"max\"]],\n",
    "                    \"tuning_policy\": \"allow short excursions within full envelope during gates\",\n",
    "                    \"priority\": \"HIGH\"\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "\n",
    "def make_floquet_drive_modes():\n",
    "    # Floquet specifics are not in the map; define waveform-level modes.\n",
    "    return [\n",
    "        {\n",
    "            \"mode_name\": \"TimeCrystal_Lock\",\n",
    "            \"description\": \"Fundamental Floquet drive establishing the time-crystal state.\",\n",
    "            \"target_profile\": {\n",
    "                \"drive_frequency_THz\": recipe.get(\"LASER_FREQ_THz\", 10.5),\n",
    "                \"subharmonic_ratio\": 2.0,      # period-doubled response\n",
    "                \"duty_cycle\": 0.5,\n",
    "                \"modulation_depth\": 0.15\n",
    "            },\n",
    "            \"controls\": [\n",
    "                {\n",
    "                    \"parameter\": \"drive_freq_THz\",\n",
    "                    \"nominal\": recipe.get(\"LASER_FREQ_THz\", 10.5),\n",
    "                    \"range\": [10.48, 10.52],\n",
    "                    \"tuning_policy\": \"locked via femtosecond laser, active feedback\",\n",
    "                    \"priority\": \"CRITICAL\"\n",
    "                },\n",
    "                {\n",
    "                    \"parameter\": \"drive_amplitude_rel\",\n",
    "                    \"nominal\": 1.0,\n",
    "                    \"range\": [0.8, 1.2],\n",
    "                    \"tuning_policy\": \"adjust amplitude to maintain subharmonic response\",\n",
    "                    \"priority\": \"HIGH\"\n",
    "                },\n",
    "                {\n",
    "                    \"parameter\": \"subharmonic_ratio\",\n",
    "                    \"nominal\": 2.0,\n",
    "                    \"range\": [1.8, 2.2],\n",
    "                    \"tuning_policy\": \"monitor spectral peaks, enforce period doubling\",\n",
    "                    \"priority\": \"HIGH\"\n",
    "                }\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"mode_name\": \"Calibration_Sweep\",\n",
    "            \"description\": \"Slow sweep of drive parameters to map stability lobes and update envelopes.\",\n",
    "            \"target_profile\": {\n",
    "                \"sweep_span_THz\": 0.04,\n",
    "                \"max_runtime_s\": 600.0,\n",
    "                \"update_sensitivity_maps\": True\n",
    "            },\n",
    "            \"controls\": [\n",
    "                {\n",
    "                    \"parameter\": \"drive_freq_THz\",\n",
    "                    \"nominal\": recipe.get(\"LASER_FREQ_THz\", 10.5),\n",
    "                    \"range\": [10.46, 10.54],\n",
    "                    \"tuning_policy\": \"scan frequency; record coherence & yield per point\",\n",
    "                    \"priority\": \"MEDIUM\"\n",
    "                },\n",
    "                {\n",
    "                    \"parameter\": \"drive_amplitude_rel\",\n",
    "                    \"nominal\": 1.0,\n",
    "                    \"range\": [0.6, 1.4],\n",
    "                    \"tuning_policy\": \"scan amplitude during calibration only\",\n",
    "                    \"priority\": \"MEDIUM\"\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "\n",
    "def make_rashba_modes(unit):\n",
    "    r_ctrl = unit[\"controls\"][0]\n",
    "    base_nom = nominal_from_recipe(\"RASHBA_COUPLING\", r_ctrl[\"nominal\"])\n",
    "    return [\n",
    "        {\n",
    "            \"mode_name\": \"Material_Setpoint\",\n",
    "            \"description\": \"Static Rashba coupling set by growth and fine-tuned via gate bias.\",\n",
    "            \"target_profile\": {\n",
    "                \"rashba_target_eV\": base_nom,\n",
    "                \"allowed_variation_eV\": 0.25 * (r_ctrl[\"max\"] - r_ctrl[\"min\"])\n",
    "            },\n",
    "            \"controls\": [\n",
    "                {\n",
    "                    \"parameter\": r_ctrl[\"parameter\"],\n",
    "                    \"nominal\": base_nom,\n",
    "                    \"range\": [r_ctrl[\"min\"], r_ctrl[\"max\"]],\n",
    "                    \"tuning_policy\": \"calibrate at cooldown; minor drift-corrections only\",\n",
    "                    \"priority\": \"HIGH\"\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "\n",
    "def make_zeeman_modes(unit):\n",
    "    z_ctrl = unit[\"controls\"][0]\n",
    "    base_nom = nominal_from_recipe(\"ZEEMAN_FIELD\", z_ctrl[\"nominal\"])\n",
    "    return [\n",
    "        {\n",
    "            \"mode_name\": \"Static_Field\",\n",
    "            \"description\": \"DC Zeeman field to place nanowire in topological regime.\",\n",
    "            \"target_profile\": {\n",
    "                \"field_target_T\": base_nom,\n",
    "                \"allowed_variation_T\": 0.25 * (z_ctrl[\"max\"] - z_ctrl[\"min\"])\n",
    "            },\n",
    "            \"controls\": [\n",
    "                {\n",
    "                    \"parameter\": z_ctrl[\"parameter\"],\n",
    "                    \"nominal\": base_nom,\n",
    "                    \"range\": [z_ctrl[\"min\"], z_ctrl[\"max\"]],\n",
    "                    \"tuning_policy\": \"ramp slowly; minimize eddy currents and heating\",\n",
    "                    \"priority\": \"HIGH\"\n",
    "                }\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"mode_name\": \"Field_Scan_Calibration\",\n",
    "            \"description\": \"Slow field scan to verify topological phase boundaries against sensitivity map.\",\n",
    "            \"target_profile\": {\n",
    "                \"scan_span_T\": 0.01,\n",
    "                \"max_runtime_s\": 900.0\n",
    "            },\n",
    "            \"controls\": [\n",
    "                {\n",
    "                    \"parameter\": z_ctrl[\"parameter\"],\n",
    "                    \"nominal\": base_nom,\n",
    "                    \"range\": [z_ctrl[\"min\"], z_ctrl[\"max\"]],\n",
    "                    \"tuning_policy\": \"oscillatory scan within allowed window during calibration only\",\n",
    "                    \"priority\": \"MEDIUM\"\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "\n",
    "def make_laser_modes(unit):\n",
    "    f_ctrl = unit[\"controls\"][0]\n",
    "    base_nom = nominal_from_recipe(\"LASER_FREQ_THz\", f_ctrl[\"nominal\"])\n",
    "    return [\n",
    "        {\n",
    "            \"mode_name\": \"Frequency_Locked\",\n",
    "            \"description\": \"Laser locked to THz drive frequency with femtosecond stability.\",\n",
    "            \"target_profile\": {\n",
    "                \"freq_target_THz\": base_nom,\n",
    "                \"freq_tolerance_THz\": 0.001,\n",
    "                \"timing_jitter_fs_rms\": 10.0\n",
    "            },\n",
    "            \"controls\": [\n",
    "                {\n",
    "                    \"parameter\": f_ctrl[\"parameter\"],\n",
    "                    \"nominal\": base_nom,\n",
    "                    \"range\": [f_ctrl[\"min\"], f_ctrl[\"max\"]],\n",
    "                    \"tuning_policy\": \"PLL lock; active compensation for slow drift\",\n",
    "                    \"priority\": \"CRITICAL\"\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "\n",
    "def make_thermal_modes():\n",
    "    return [\n",
    "        {\n",
    "            \"mode_name\": \"Base_Temperature\",\n",
    "            \"description\": \"Dilution refrigerator at ~10 mK with full shielding.\",\n",
    "            \"target_profile\": {\n",
    "                \"base_temp_mK\": 10.0,\n",
    "                \"max_temp_mK\": 15.0,\n",
    "                \"field_cool_protocol\": \"zero-field-cool then ramp Zeeman\"\n",
    "            },\n",
    "            \"controls\": [\n",
    "                {\n",
    "                    \"parameter\": \"fridge_setpoint_mK\",\n",
    "                    \"nominal\": 10.0,\n",
    "                    \"range\": [8.0, 15.0],\n",
    "                    \"tuning_policy\": \"PID fridge control; keep < 12 mK during operation\",\n",
    "                    \"priority\": \"HIGH\"\n",
    "                },\n",
    "                {\n",
    "                    \"parameter\": \"shield_state\",\n",
    "                    \"nominal\": 1.0,\n",
    "                    \"range\": [0.0, 1.0],\n",
    "                    \"tuning_policy\": \"1 = closed; interlocks prevent operation at 0\",\n",
    "                    \"priority\": \"CRITICAL\"\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "\n",
    "def make_yield_modes():\n",
    "    return [\n",
    "        {\n",
    "            \"mode_name\": \"MonteCarlo_Qualification\",\n",
    "            \"description\": \"Reproduces 10,000-point jitter stress test to qualify device yield.\",\n",
    "            \"target_profile\": {\n",
    "                \"target_yield_fraction\": 0.32,\n",
    "                \"num_samples\": 10000\n",
    "            },\n",
    "            \"controls\": [\n",
    "                {\n",
    "                    \"parameter\": \"jitter_std_freq_ppm\",\n",
    "                    \"nominal\": 5.0,\n",
    "                    \"range\": [1.0, 20.0],\n",
    "                    \"tuning_policy\": \"simulate and measure coherence under specified jitter\",\n",
    "                    \"priority\": \"MEDIUM\"\n",
    "                },\n",
    "                {\n",
    "                    \"parameter\": \"fabrication_offset_sigma\",\n",
    "                    \"nominal\": 1.0,\n",
    "                    \"range\": [0.5, 3.0],\n",
    "                    \"tuning_policy\": \"model array of devices across wafer\",\n",
    "                    \"priority\": \"MEDIUM\"\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "\n",
    "def make_error_correction_modes():\n",
    "    return [\n",
    "        {\n",
    "            \"mode_name\": \"Logical_Run\",\n",
    "            \"description\": \"Continuous syndrome extraction and correction on logical qubits.\",\n",
    "            \"target_profile\": {\n",
    "                \"code_type\": \"surface_code_majorana\",\n",
    "                \"code_distance\": 9,\n",
    "                \"cycle_time_ns\": 100.0\n",
    "            },\n",
    "            \"controls\": [\n",
    "                {\n",
    "                    \"parameter\": \"code_distance\",\n",
    "                    \"nominal\": 9,\n",
    "                    \"range\": [5, 17],\n",
    "                    \"tuning_policy\": \"trade coherence budget vs overhead\",\n",
    "                    \"priority\": \"HIGH\"\n",
    "                },\n",
    "                {\n",
    "                    \"parameter\": \"syndrome_cycle_time_ns\",\n",
    "                    \"nominal\": 100.0,\n",
    "                    \"range\": [50.0, 200.0],\n",
    "                    \"tuning_policy\": \"match to gate times and decoherence\",\n",
    "                    \"priority\": \"HIGH\"\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "\n",
    "def make_control_fabric_modes(unit):\n",
    "    # Trial_ID was used as a proxy; reinterpret as experiment indexing\n",
    "    return [\n",
    "        {\n",
    "            \"mode_name\": \"Experiment_Scheduler\",\n",
    "            \"description\": \"Assigns trial IDs and sequences pulses for calibration and production.\",\n",
    "            \"target_profile\": {\n",
    "                \"max_parallel_experiments\": 64,\n",
    "                \"max_trial_id\": unit[\"controls\"][0][\"max\"]\n",
    "            },\n",
    "            \"controls\": [\n",
    "                {\n",
    "                    \"parameter\": \"max_parallel_experiments\",\n",
    "                    \"nominal\": 32,\n",
    "                    \"range\": [8, 128],\n",
    "                    \"tuning_policy\": \"set based on control hardware bandwidth\",\n",
    "                    \"priority\": \"MEDIUM\"\n",
    "                },\n",
    "                {\n",
    "                    \"parameter\": \"trial_id_stride\",\n",
    "                    \"nominal\": 1,\n",
    "                    \"range\": [1, 100],\n",
    "                    \"tuning_policy\": \"encode experiment metadata in ID spacing\",\n",
    "                    \"priority\": \"LOW\"\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "\n",
    "def make_calibration_modes():\n",
    "    return [\n",
    "        {\n",
    "            \"mode_name\": \"Daily_Calibration\",\n",
    "            \"description\": \"Automated daily tune-up across Rashba, Zeeman, and laser parameters.\",\n",
    "            \"target_profile\": {\n",
    "                \"duration_minutes\": 60,\n",
    "                \"max_allowed_drift_sigma\": 2.0\n",
    "            },\n",
    "            \"controls\": [\n",
    "                {\n",
    "                    \"parameter\": \"calibration_interval_hours\",\n",
    "                    \"nominal\": 24.0,\n",
    "                    \"range\": [4.0, 48.0],\n",
    "                    \"tuning_policy\": \"shorten interval if drift exceeds threshold\",\n",
    "                    \"priority\": \"MEDIUM\"\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# D. BUILD MODES FOR ALL UNITS\n",
    "# -------------------------------------------------------------\n",
    "for unit in base_blueprint[\"processing_units\"]:\n",
    "    name = unit[\"name\"]\n",
    "    unit_entry = {\n",
    "        \"name\": name,\n",
    "        \"role\": unit[\"role\"],\n",
    "        \"modes\": []\n",
    "    }\n",
    "\n",
    "    if name == \"Majorana_QPU_Core\":\n",
    "        unit_entry[\"modes\"] = make_majorana_modes(unit)\n",
    "    elif name == \"Floquet_Drive_Unit\":\n",
    "        unit_entry[\"modes\"] = make_floquet_drive_modes()\n",
    "    elif name == \"Rashba_Field_Controller\":\n",
    "        unit_entry[\"modes\"] = make_rashba_modes(unit)\n",
    "    elif name == \"Zeeman_Magnet_Unit\":\n",
    "        unit_entry[\"modes\"] = make_zeeman_modes(unit)\n",
    "    elif name == \"Laser_Coherence_Unit\":\n",
    "        unit_entry[\"modes\"] = make_laser_modes(unit)\n",
    "    elif name == \"Thermal_Shielding_Unit\":\n",
    "        unit_entry[\"modes\"] = make_thermal_modes()\n",
    "    elif name == \"Yield_Optimization_Unit\":\n",
    "        unit_entry[\"modes\"] = make_yield_modes()\n",
    "    elif name == \"Error_Correction_Unit\":\n",
    "        unit_entry[\"modes\"] = make_error_correction_modes()\n",
    "    elif name == \"Control_Fabric_Unit\":\n",
    "        unit_entry[\"modes\"] = make_control_fabric_modes(unit)\n",
    "    elif name == \"Calibration_Unit\":\n",
    "        unit_entry[\"modes\"] = make_calibration_modes()\n",
    "    else:\n",
    "        unit_entry[\"modes\"] = []\n",
    "\n",
    "    system_modes[\"units\"].append(unit_entry)\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# E. MERGED ‚ÄúFULL SPEC‚Äù ARTIFACT\n",
    "# -------------------------------------------------------------\n",
    "full_spec = {\n",
    "    \"meta\": {\n",
    "        \"version\": \"titan-singularity-fullspec-v1\",\n",
    "        \"base_blueprint\": base_blueprint[\"meta\"][\"version\"],\n",
    "        \"modes_version\": system_modes[\"meta\"][\"version\"],\n",
    "        \"target\": meta.get(\"target\", \"0.1nm Time Crystal\")\n",
    "    },\n",
    "    \"specs\": specs,\n",
    "    \"control_surface\": base_blueprint,\n",
    "    \"system_modes\": system_modes\n",
    "}\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# F. SAVE JSON OUTPUTS\n",
    "# -------------------------------------------------------------\n",
    "modes_path = \"titan_0_1nm_system_modes.json\"\n",
    "fullspec_path = \"titan_0_1nm_full_spec.json\"\n",
    "\n",
    "with open(modes_path, \"w\") as f:\n",
    "    json.dump(system_modes, f, indent=2)\n",
    "\n",
    "with open(fullspec_path, \"w\") as f:\n",
    "    json.dump(full_spec, f, indent=2)\n",
    "\n",
    "print(\"EXPORT COMPLETE:\")\n",
    "print(\" -\", modes_path)\n",
    "print(\" -\", fullspec_path)\n",
    "for u in system_modes[\"units\"]:\n",
    "    print(f\"   * {u['name']}: {len(u['modes'])} modes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "adbf41ba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-22T23:34:23.073537Z",
     "iopub.status.busy": "2026-01-22T23:34:23.073277Z",
     "iopub.status.idle": "2026-01-22T23:34:23.094320Z",
     "shell.execute_reply": "2026-01-22T23:34:23.093401Z"
    },
    "papermill": {
     "duration": 0.029932,
     "end_time": "2026-01-22T23:34:23.096007",
     "exception": false,
     "start_time": "2026-01-22T23:34:23.066075",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SYSTEM ONLINE :: TITAN 0.1nm SINGULARITY CELL 5\n",
      "Loaded modes version: titan-singularity-cell4-v1\n",
      "EXPORT COMPLETE :: titan_0_1nm_experiment_plans.json\n",
      " - floquet_calibration: 2 experiments\n",
      " - zeeman_phase: 2 experiments\n",
      " - yield_qualification: 2 experiments\n"
     ]
    }
   ],
   "source": [
    "# TITAN 0.1nm SINGULARITY ‚Äì CELL 5\n",
    "# Experiment Campaign Generator\n",
    "\n",
    "import json\n",
    "import math\n",
    "\n",
    "print(\"SYSTEM ONLINE :: TITAN 0.1nm SINGULARITY CELL 5\")\n",
    "\n",
    "MODES_PATH = \"titan_0_1nm_system_modes.json\"\n",
    "\n",
    "with open(MODES_PATH, \"r\") as f:\n",
    "    modes_spec = json.load(f)\n",
    "\n",
    "print(\"Loaded modes version:\", modes_spec[\"meta\"][\"version\"])\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# Helpers\n",
    "# -------------------------------------------------------------\n",
    "def find_unit(units, name):\n",
    "    for u in units:\n",
    "        if u[\"name\"] == name:\n",
    "            return u\n",
    "    return None\n",
    "\n",
    "units = modes_spec[\"units\"]\n",
    "\n",
    "floquet_unit   = find_unit(units, \"Floquet_Drive_Unit\")\n",
    "zeeman_unit    = find_unit(units, \"Zeeman_Magnet_Unit\")\n",
    "yield_unit     = find_unit(units, \"Yield_Optimization_Unit\")\n",
    "majorana_unit  = find_unit(units, \"Majorana_QPU_Core\")\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 1. Floquet Drive Calibration Experiments\n",
    "# -------------------------------------------------------------\n",
    "floquet_experiments = []\n",
    "\n",
    "if floquet_unit is not None:\n",
    "    # TimeCrystal_Lock mode\n",
    "    lock_mode = next(m for m in floquet_unit[\"modes\"] if m[\"mode_name\"] == \"TimeCrystal_Lock\")\n",
    "    lock_freq   = lock_mode[\"target_profile\"][\"drive_frequency_THz\"]\n",
    "    lock_ctrls  = {c[\"parameter\"]: c for c in lock_mode[\"controls\"]}\n",
    "    freq_range  = lock_ctrls[\"drive_freq_THz\"][\"range\"]\n",
    "    \n",
    "    # Calibration_Sweep mode\n",
    "    sweep_mode = next(m for m in floquet_unit[\"modes\"] if m[\"mode_name\"] == \"Calibration_Sweep\")\n",
    "    sweep_span = sweep_mode[\"target_profile\"][\"sweep_span_THz\"]\n",
    "    sweep_ctrls = {c[\"parameter\"]: c for c in sweep_mode[\"controls\"]}\n",
    "    sweep_freq_range = sweep_ctrls[\"drive_freq_THz\"][\"range\"]\n",
    "    \n",
    "    # Experiment 1: High-resolution lock neighborhood scan\n",
    "    n_points_lock = 41  # e.g., ~1 GHz resolution over 40 GHz window\n",
    "    f_min_lock = max(freq_range[0], lock_freq - sweep_span / 2.0)\n",
    "    f_max_lock = min(freq_range[1], lock_freq + sweep_span / 2.0)\n",
    "    lock_freqs = [f_min_lock + i * (f_max_lock - f_min_lock) / (n_points_lock - 1)\n",
    "                  for i in range(n_points_lock)]\n",
    "    \n",
    "    floquet_experiments.append({\n",
    "        \"name\": \"Floquet_Lock_Neighborhood\",\n",
    "        \"description\": \"Fine scan around lock frequency to refine time-crystal stability window.\",\n",
    "        \"unit\": \"Floquet_Drive_Unit\",\n",
    "        \"mode\": \"Calibration_Sweep\",\n",
    "        \"sweep_type\": \"frequency\",\n",
    "        \"parameters\": {\n",
    "            \"drive_freq_THz_points\": lock_freqs,\n",
    "            \"drive_amplitude_rel\": 1.0,\n",
    "            \"subharmonic_ratio_target\": 2.0\n",
    "        },\n",
    "        \"measurements\": [\n",
    "            \"coherence_time\",\n",
    "            \"subharmonic_peak_amplitude\",\n",
    "            \"yield_fraction\"\n",
    "        ]\n",
    "    })\n",
    "    \n",
    "    # Experiment 2: Amplitude scan at fixed lock frequency\n",
    "    n_points_amp = 21\n",
    "    amp_min, amp_max = lock_ctrls[\"drive_amplitude_rel\"][\"range\"]\n",
    "    amp_points = [amp_min + i * (amp_max - amp_min) / (n_points_amp - 1)\n",
    "                  for i in range(n_points_amp)]\n",
    "    \n",
    "    floquet_experiments.append({\n",
    "        \"name\": \"Floquet_Amplitude_Response\",\n",
    "        \"description\": \"Scan drive amplitude at lock frequency to map subharmonic response.\",\n",
    "        \"unit\": \"Floquet_Drive_Unit\",\n",
    "        \"mode\": \"TimeCrystal_Lock\",\n",
    "        \"sweep_type\": \"amplitude\",\n",
    "        \"parameters\": {\n",
    "            \"drive_freq_THz\": lock_freq,\n",
    "            \"drive_amplitude_rel_points\": amp_points,\n",
    "            \"subharmonic_ratio_target\": 2.0\n",
    "        },\n",
    "        \"measurements\": [\n",
    "            \"coherence_time\",\n",
    "            \"subharmonic_peak_amplitude\"\n",
    "        ]\n",
    "    })\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 2. Zeeman Field Phase-Boundary Experiments\n",
    "# -------------------------------------------------------------\n",
    "zeeman_experiments = []\n",
    "\n",
    "if zeeman_unit is not None and majorana_unit is not None:\n",
    "    z_mode_static = next(m for m in zeeman_unit[\"modes\"]\n",
    "                         if m[\"mode_name\"] == \"Static_Field\")\n",
    "    z_ctrl = z_mode_static[\"controls\"][0]\n",
    "    B_min, B_max = z_ctrl[\"range\"]\n",
    "    B_mid = z_mode_static[\"target_profile\"][\"field_target_T\"]\n",
    "    \n",
    "    gap_ctrl = majorana_unit[\"modes\"][0][\"controls\"][0]\n",
    "    \n",
    "    # Experiment 3: Zeeman scan across full safe range\n",
    "    n_points_B = 51\n",
    "    B_points = [B_min + i * (B_max - B_min) / (n_points_B - 1)\n",
    "                for i in range(n_points_B)]\n",
    "    \n",
    "    zeeman_experiments.append({\n",
    "        \"name\": \"Zeeman_Phase_Boundary_Scan\",\n",
    "        \"description\": \"Scan Zeeman field to locate transitions into/out of the topological regime.\",\n",
    "        \"unit\": \"Zeeman_Magnet_Unit\",\n",
    "        \"mode\": \"Field_Scan_Calibration\",\n",
    "        \"sweep_type\": \"field\",\n",
    "        \"parameters\": {\n",
    "            \"Zeeman_T_points\": B_points\n",
    "        },\n",
    "        \"measurements\": [\n",
    "            \"gap_meV\",\n",
    "            \"coherence_time\",\n",
    "            \"parity_stability\"\n",
    "        ]\n",
    "    })\n",
    "    \n",
    "    # Experiment 4: Zeeman modulation during gate operation\n",
    "    zeeman_experiments.append({\n",
    "        \"name\": \"Zeeman_During_Gates\",\n",
    "        \"description\": \"Test robustness of gate operations to small Zeeman modulations.\",\n",
    "        \"unit\": \"Zeeman_Magnet_Unit\",\n",
    "        \"mode\": \"Field_Scan_Calibration\",\n",
    "        \"sweep_type\": \"field_modulation\",\n",
    "        \"parameters\": {\n",
    "            \"Zeeman_center_T\": B_mid,\n",
    "            \"Zeeman_modulation_delta_T\": 0.001,\n",
    "            \"num_cycles\": 100\n",
    "        },\n",
    "        \"measurements\": [\n",
    "            \"gate_fidelity\",\n",
    "            \"error_rate_per_cycle\"\n",
    "        ]\n",
    "    })\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 3. Yield Monte Carlo Qualification Experiments\n",
    "# -------------------------------------------------------------\n",
    "yield_experiments = []\n",
    "\n",
    "if yield_unit is not None:\n",
    "    mc_mode = yield_unit[\"modes\"][0]\n",
    "    profile = mc_mode[\"target_profile\"]\n",
    "    controls = {c[\"parameter\"]: c for c in mc_mode[\"controls\"]}\n",
    "    \n",
    "    target_yield = profile[\"target_yield_fraction\"]\n",
    "    \n",
    "    # Experiment 5: Reproduce original 10k-point MC\n",
    "    yield_experiments.append({\n",
    "        \"name\": \"Yield_MC_Reproduction\",\n",
    "        \"description\": \"Reproduce 10,000-point jitter stress test to validate original yield estimate.\",\n",
    "        \"unit\": \"Yield_Optimization_Unit\",\n",
    "        \"mode\": \"MonteCarlo_Qualification\",\n",
    "        \"parameters\": {\n",
    "            \"num_samples\": profile[\"num_samples\"],\n",
    "            \"jitter_std_freq_ppm\": controls[\"jitter_std_freq_ppm\"][\"nominal\"],\n",
    "            \"fabrication_offset_sigma\": controls[\"fabrication_offset_sigma\"][\"nominal\"]\n",
    "        },\n",
    "        \"acceptance_criteria\": {\n",
    "            \"yield_fraction_min\": 0.25,\n",
    "            \"yield_fraction_target\": target_yield\n",
    "        },\n",
    "        \"measurements\": [\n",
    "            \"yield_fraction\",\n",
    "            \"coherence_distribution\",\n",
    "            \"failure_mode_statistics\"\n",
    "        ]\n",
    "    })\n",
    "    \n",
    "    # Experiment 6: Yield vs jitter curve\n",
    "    jitter_min, jitter_max = controls[\"jitter_std_freq_ppm\"][\"range\"]\n",
    "    n_points_jitter = 9\n",
    "    jitter_points = [jitter_min + i * (jitter_max - jitter_min) / (n_points_jitter - 1)\n",
    "                     for i in range(n_points_jitter)]\n",
    "    \n",
    "    yield_experiments.append({\n",
    "        \"name\": \"Yield_vs_Jitter_Curve\",\n",
    "        \"description\": \"Scan laser jitter and measure yield to map robustness curve.\",\n",
    "        \"unit\": \"Yield_Optimization_Unit\",\n",
    "        \"mode\": \"MonteCarlo_Qualification\",\n",
    "        \"parameters\": {\n",
    "            \"num_samples\": 2000,\n",
    "            \"jitter_std_freq_ppm_points\": jitter_points,\n",
    "            \"fabrication_offset_sigma\": controls[\"fabrication_offset_sigma\"][\"nominal\"]\n",
    "        },\n",
    "        \"measurements\": [\n",
    "            \"yield_fraction\",\n",
    "            \"coherence_distribution\"\n",
    "        ]\n",
    "    })\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 4. Assemble Experiment Plan Artifact\n",
    "# -------------------------------------------------------------\n",
    "experiment_plans = {\n",
    "    \"meta\": {\n",
    "        \"version\": \"titan-singularity-expplans-v1\",\n",
    "        \"derived_from_modes\": modes_spec[\"meta\"][\"version\"],\n",
    "        \"target\": modes_spec[\"meta\"][\"target\"]\n",
    "    },\n",
    "    \"experiments\": {\n",
    "        \"floquet_calibration\": floquet_experiments,\n",
    "        \"zeeman_phase\": zeeman_experiments,\n",
    "        \"yield_qualification\": yield_experiments\n",
    "    }\n",
    "}\n",
    "\n",
    "OUT_PATH = \"titan_0_1nm_experiment_plans.json\"\n",
    "with open(OUT_PATH, \"w\") as f:\n",
    "    json.dump(experiment_plans, f, indent=2)\n",
    "\n",
    "print(\"EXPORT COMPLETE ::\", OUT_PATH)\n",
    "for group, exps in experiment_plans[\"experiments\"].items():\n",
    "    print(f\" - {group}: {len(exps)} experiments\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8470f2d5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-22T23:34:23.108688Z",
     "iopub.status.busy": "2026-01-22T23:34:23.108374Z",
     "iopub.status.idle": "2026-01-22T23:34:23.122055Z",
     "shell.execute_reply": "2026-01-22T23:34:23.121172Z"
    },
    "papermill": {
     "duration": 0.021944,
     "end_time": "2026-01-22T23:34:23.123583",
     "exception": false,
     "start_time": "2026-01-22T23:34:23.101639",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SYSTEM ONLINE :: TITAN 0.1nm SINGULARITY CELL 5B\n",
      "Loaded exp plan version: titan-singularity-expplans-v1\n",
      "EXPORT COMPLETE :: titan_0_1nm_experiment_plans_v2.json\n",
      " - floquet_calibration:\n",
      "   * Floquet_Lock_Neighborhood | priority=CRITICAL | per_point_s=2.0 | reps=5 | depends_on=[]\n",
      "   * Floquet_Amplitude_Response | priority=HIGH | per_point_s=1.5 | reps=3 | depends_on=['Floquet_Lock_Neighborhood']\n",
      " - zeeman_phase:\n",
      "   * Zeeman_Phase_Boundary_Scan | priority=HIGH | per_point_s=3.0 | reps=3 | depends_on=['Floquet_Lock_Neighborhood']\n",
      "   * Zeeman_During_Gates | priority=HIGH | per_point_s=4.0 | reps=10 | depends_on=['Floquet_Lock_Neighborhood', 'Floquet_Amplitude_Response', 'Zeeman_Phase_Boundary_Scan']\n",
      " - yield_qualification:\n",
      "   * Yield_MC_Reproduction | priority=MEDIUM | per_point_s=0.01 | reps=1 | depends_on=['Floquet_Lock_Neighborhood']\n",
      "   * Yield_vs_Jitter_Curve | priority=MEDIUM | per_point_s=0.02 | reps=1 | depends_on=['Yield_MC_Reproduction']\n"
     ]
    }
   ],
   "source": [
    "# TITAN 0.1nm SINGULARITY ‚Äì CELL 5 (UPGRADE)\n",
    "# Add runtime metadata + priority/dependencies\n",
    "\n",
    "import json\n",
    "\n",
    "print(\"SYSTEM ONLINE :: TITAN 0.1nm SINGULARITY CELL 5B\")\n",
    "\n",
    "IN_PATH  = \"titan_0_1nm_experiment_plans.json\"\n",
    "OUT_PATH = \"titan_0_1nm_experiment_plans_v2.json\"\n",
    "\n",
    "with open(IN_PATH, \"r\") as f:\n",
    "    plans = json.load(f)\n",
    "\n",
    "print(\"Loaded exp plan version:\", plans[\"meta\"][\"version\"])\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# Helper to attach metadata\n",
    "# -------------------------------------------------------------\n",
    "def add_metadata(exp, defaults):\n",
    "    # Attach or override runtime + scheduling fields\n",
    "    exp[\"runtime\"] = {\n",
    "        \"estimated_duration_per_point_s\": defaults[\"per_point_s\"],\n",
    "        \"repetitions\": defaults[\"repetitions\"],\n",
    "        \"randomize_order\": defaults[\"randomize\"]\n",
    "    }\n",
    "    exp[\"priority\"] = defaults[\"priority\"]\n",
    "    exp[\"depends_on\"] = defaults.get(\"depends_on\", [])\n",
    "    return exp\n",
    "\n",
    "exps = plans[\"experiments\"]\n",
    "\n",
    "# Short names to refer to dependencies\n",
    "name_to_group = {}\n",
    "for group_name, group_exps in exps.items():\n",
    "    for e in group_exps:\n",
    "        name_to_group[e[\"name\"]] = group_name\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 1. Floquet calibration experiments\n",
    "# -------------------------------------------------------------\n",
    "for e in exps.get(\"floquet_calibration\", []):\n",
    "    if e[\"name\"] == \"Floquet_Lock_Neighborhood\":\n",
    "        add_metadata(e, {\n",
    "            \"per_point_s\": 2.0,        # e.g. 2 s per freq point\n",
    "            \"repetitions\": 5,\n",
    "            \"randomize\": False,        # monotonic sweep for lock finding\n",
    "            \"priority\": \"CRITICAL\",\n",
    "            \"depends_on\": []           # starting point\n",
    "        })\n",
    "    elif e[\"name\"] == \"Floquet_Amplitude_Response\":\n",
    "        add_metadata(e, {\n",
    "            \"per_point_s\": 1.5,\n",
    "            \"repetitions\": 3,\n",
    "            \"randomize\": True,         # randomize amplitude order to de-correlate drift\n",
    "            \"priority\": \"HIGH\",\n",
    "            \"depends_on\": [\"Floquet_Lock_Neighborhood\"]\n",
    "        })\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 2. Zeeman phase experiments\n",
    "# -------------------------------------------------------------\n",
    "for e in exps.get(\"zeeman_phase\", []):\n",
    "    if e[\"name\"] == \"Zeeman_Phase_Boundary_Scan\":\n",
    "        add_metadata(e, {\n",
    "            \"per_point_s\": 3.0,\n",
    "            \"repetitions\": 3,\n",
    "            \"randomize\": False,        # ramp Zeeman smoothly\n",
    "            \"priority\": \"HIGH\",\n",
    "            \"depends_on\": [\"Floquet_Lock_Neighborhood\"]\n",
    "        })\n",
    "    elif e[\"name\"] == \"Zeeman_During_Gates\":\n",
    "        add_metadata(e, {\n",
    "            \"per_point_s\": 4.0,\n",
    "            \"repetitions\": 10,\n",
    "            \"randomize\": True,\n",
    "            \"priority\": \"HIGH\",\n",
    "            \"depends_on\": [\n",
    "                \"Floquet_Lock_Neighborhood\",\n",
    "                \"Floquet_Amplitude_Response\",\n",
    "                \"Zeeman_Phase_Boundary_Scan\"\n",
    "            ]\n",
    "        })\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 3. Yield qualification experiments\n",
    "# -------------------------------------------------------------\n",
    "for e in exps.get(\"yield_qualification\", []):\n",
    "    if e[\"name\"] == \"Yield_MC_Reproduction\":\n",
    "        add_metadata(e, {\n",
    "            \"per_point_s\": 0.01,       # MC samples are simulated or fast offline\n",
    "            \"repetitions\": 1,\n",
    "            \"randomize\": True,\n",
    "            \"priority\": \"MEDIUM\",\n",
    "            \"depends_on\": [\"Floquet_Lock_Neighborhood\"]\n",
    "        })\n",
    "    elif e[\"name\"] == \"Yield_vs_Jitter_Curve\":\n",
    "        add_metadata(e, {\n",
    "            \"per_point_s\": 0.02,\n",
    "            \"repetitions\": 1,\n",
    "            \"randomize\": True,\n",
    "            \"priority\": \"MEDIUM\",\n",
    "            \"depends_on\": [\"Yield_MC_Reproduction\"]\n",
    "        })\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 4. Bump meta version and export\n",
    "# -------------------------------------------------------------\n",
    "plans[\"meta\"][\"version\"] = \"titan-singularity-expplans-v2\"\n",
    "plans[\"meta\"][\"notes\"] = (\n",
    "    \"Added runtime estimates, repetitions, randomization flags, and priority/dependency graph \"\n",
    "    \"for scheduler integration.\"\n",
    ")\n",
    "\n",
    "with open(OUT_PATH, \"w\") as f:\n",
    "    json.dump(plans, f, indent=2)\n",
    "\n",
    "print(\"EXPORT COMPLETE ::\", OUT_PATH)\n",
    "for group, group_exps in plans[\"experiments\"].items():\n",
    "    print(f\" - {group}:\")\n",
    "    for e in group_exps:\n",
    "        rt = e.get(\"runtime\", {})\n",
    "        print(\n",
    "            f\"   * {e['name']} | priority={e.get('priority')} | \"\n",
    "            f\"per_point_s={rt.get('estimated_duration_per_point_s')} | \"\n",
    "            f\"reps={rt.get('repetitions')} | depends_on={e.get('depends_on', [])}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fdf9ea3b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-22T23:34:23.136291Z",
     "iopub.status.busy": "2026-01-22T23:34:23.135997Z",
     "iopub.status.idle": "2026-01-22T23:34:23.151528Z",
     "shell.execute_reply": "2026-01-22T23:34:23.150717Z"
    },
    "papermill": {
     "duration": 0.023696,
     "end_time": "2026-01-22T23:34:23.153057",
     "exception": false,
     "start_time": "2026-01-22T23:34:23.129361",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SYSTEM ONLINE :: TITAN 0.1nm SINGULARITY CELL 6B\n",
      "Loaded spec version: titan-singularity-fullspec-v1\n",
      "EXPORT COMPLETE :: titan_0_1nm_control_IO_map.json\n",
      " - Mapped 16 hardware control channels.\n",
      " - Interface types used:\n",
      "   * AWG_RF_MODULATOR\n",
      "   * DAC_PRECISION_DC\n",
      "   * FPGA_CONFIG_REG\n",
      "   * GENERIC_SLOW_CONTROL\n",
      "   * MAGNET_SUPPLY_CURRENT\n",
      "   * OPTICAL_LOCK_LOOP\n",
      "   * SIMULATION_CONFIG\n",
      "   * VIRTUAL_DERIVED\n"
     ]
    }
   ],
   "source": [
    "# TITAN 0.1nm SINGULARITY ‚Äì CELL 6 (FIXED)\n",
    "# Hardware IO & Firmware Mapping\n",
    "\n",
    "import json\n",
    "\n",
    "print(\"SYSTEM ONLINE :: TITAN 0.1nm SINGULARITY CELL 6B\")\n",
    "\n",
    "FULL_SPEC_PATH = \"titan_0_1nm_full_spec.json\"\n",
    "OUT_IO_PATH = \"titan_0_1nm_control_IO_map.json\"\n",
    "\n",
    "with open(FULL_SPEC_PATH, \"r\") as f:\n",
    "    full_spec = json.load(f)\n",
    "\n",
    "print(\"Loaded spec version:\", full_spec[\"meta\"][\"version\"])\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# Helper: extract safe range + nominal from a control block\n",
    "# -------------------------------------------------------------\n",
    "def extract_range_and_nominal(ctrl):\n",
    "    # Modes use \"range\": [min, max]; control_surface uses \"min\"/\"max\".\n",
    "    if \"range\" in ctrl and isinstance(ctrl[\"range\"], list) and len(ctrl[\"range\"]) == 2:\n",
    "        cmin, cmax = ctrl[\"range\"]\n",
    "    else:\n",
    "        cmin = ctrl.get(\"min\", 0.0)\n",
    "        cmax = ctrl.get(\"max\", 1.0)\n",
    "    nominal = ctrl.get(\"nominal\", (cmin + cmax) / 2.0)\n",
    "    return float(cmin), float(cmax), float(nominal)\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# IO Channel Definitions\n",
    "# -------------------------------------------------------------\n",
    "def map_parameter_to_io(unit_name, ctrl):\n",
    "    param = ctrl[\"parameter\"]\n",
    "    cmin, cmax, nominal = extract_range_and_nominal(ctrl)\n",
    "\n",
    "    io_def = {\n",
    "        \"parameter_key\": param,\n",
    "        \"unit_owner\": unit_name,\n",
    "        \"interface_type\": \"UNKNOWN\",\n",
    "        \"channel_id\": \"CH_00\",\n",
    "        \"resolution_bits\": 16,\n",
    "        \"update_rate_Hz\": 1000.0,\n",
    "        \"safe_range\": [cmin, cmax],\n",
    "        \"default_setpoint\": nominal\n",
    "    }\n",
    "\n",
    "    p = param\n",
    "\n",
    "    if \"Freq_THz\" in p or \"drive_freq\" in p:\n",
    "        io_def[\"interface_type\"] = \"OPTICAL_LOCK_LOOP\"\n",
    "        io_def[\"channel_id\"] = \"OLL_CH_01\"\n",
    "        io_def[\"resolution_bits\"] = 32\n",
    "        io_def[\"update_rate_Hz\"] = 10e6\n",
    "\n",
    "    elif \"Rashba\" in p or \"Gate\" in p:\n",
    "        io_def[\"interface_type\"] = \"DAC_PRECISION_DC\"\n",
    "        io_def[\"channel_id\"] = \"DAC_SLOT3_CH04\"\n",
    "        io_def[\"resolution_bits\"] = 20\n",
    "        io_def[\"update_rate_Hz\"] = 100e3\n",
    "\n",
    "    elif \"Zeeman\" in p or \"Field\" in p:\n",
    "        io_def[\"interface_type\"] = \"MAGNET_SUPPLY_CURRENT\"\n",
    "        io_def[\"channel_id\"] = \"PSU_MAIN_COIL\"\n",
    "        io_def[\"resolution_bits\"] = 24\n",
    "        io_def[\"update_rate_Hz\"] = 10.0\n",
    "\n",
    "    elif \"Gap\" in p or \"Majorana\" in p:\n",
    "        io_def[\"interface_type\"] = \"VIRTUAL_DERIVED\"\n",
    "        io_def[\"channel_id\"] = \"META_REG_01\"\n",
    "        io_def[\"resolution_bits\"] = 32\n",
    "\n",
    "    elif \"jitter\" in p or \"offset\" in p:\n",
    "        io_def[\"interface_type\"] = \"SIMULATION_CONFIG\"\n",
    "        io_def[\"channel_id\"] = \"SIM_CONF_0X10\"\n",
    "\n",
    "    elif \"code_distance\" in p or \"cycle_time\" in p:\n",
    "        io_def[\"interface_type\"] = \"FPGA_CONFIG_REG\"\n",
    "        io_def[\"channel_id\"] = \"FPGA_CORE_REG_04\"\n",
    "        io_def[\"resolution_bits\"] = 32\n",
    "\n",
    "    elif \"drive_amplitude\" in p:\n",
    "        io_def[\"interface_type\"] = \"AWG_RF_MODULATOR\"\n",
    "        io_def[\"channel_id\"] = \"AWG_MOD_CH01\"\n",
    "        io_def[\"resolution_bits\"] = 16\n",
    "        io_def[\"update_rate_Hz\"] = 1e9\n",
    "\n",
    "    else:\n",
    "        io_def[\"interface_type\"] = \"GENERIC_SLOW_CONTROL\"\n",
    "        io_def[\"channel_id\"] = \"SC_BUS_01\"\n",
    "\n",
    "    return io_def\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# Build IO Map\n",
    "# -------------------------------------------------------------\n",
    "io_map = {\n",
    "    \"meta\": {\n",
    "        \"version\": \"titan-singularity-io-v1\",\n",
    "        \"description\": \"Hardware channel mapping for 0.1nm Titan control stack.\",\n",
    "        \"derived_from_spec\": full_spec[\"meta\"][\"version\"]\n",
    "    },\n",
    "    \"channels\": []\n",
    "}\n",
    "\n",
    "seen_params = set()\n",
    "\n",
    "for unit in full_spec[\"system_modes\"][\"units\"]:\n",
    "    for mode in unit.get(\"modes\", []):\n",
    "        for ctrl in mode.get(\"controls\", []):\n",
    "            p_name = ctrl[\"parameter\"]\n",
    "            unique_key = f\"{unit['name']}::{p_name}\"\n",
    "            if unique_key in seen_params:\n",
    "                continue\n",
    "            channel_def = map_parameter_to_io(unit[\"name\"], ctrl)\n",
    "            channel_def[\"unique_id\"] = unique_key\n",
    "            io_map[\"channels\"].append(channel_def)\n",
    "            seen_params.add(unique_key)\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# Export\n",
    "# -------------------------------------------------------------\n",
    "with open(OUT_IO_PATH, \"w\") as f:\n",
    "    json.dump(io_map, f, indent=2)\n",
    "\n",
    "print(\"EXPORT COMPLETE ::\", OUT_IO_PATH)\n",
    "print(f\" - Mapped {len(io_map['channels'])} hardware control channels.\")\n",
    "types = sorted(set(c[\"interface_type\"] for c in io_map[\"channels\"]))\n",
    "print(\" - Interface types used:\")\n",
    "for t in types:\n",
    "    print(f\"   * {t}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce2f75c4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-22T23:34:23.166766Z",
     "iopub.status.busy": "2026-01-22T23:34:23.166253Z",
     "iopub.status.idle": "2026-01-22T23:34:23.187560Z",
     "shell.execute_reply": "2026-01-22T23:34:23.186710Z"
    },
    "papermill": {
     "duration": 0.029769,
     "end_time": "2026-01-22T23:34:23.189148",
     "exception": false,
     "start_time": "2026-01-22T23:34:23.159379",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SYSTEM ONLINE :: TITAN 0.1nm SINGULARITY CELL 6C\n",
      "Loaded IO map version: titan-singularity-io-v1\n",
      "EXPORT COMPLETE :: titan_0_1nm_control_IO_map_v2.json\n",
      " - Channels enriched: 16\n",
      "Sample channels with interlocks:\n",
      "  * Floquet_Drive_Unit::drive_freq_THz -> 1 interlocks\n",
      "  * Floquet_Drive_Unit::drive_amplitude_rel -> 1 interlocks\n",
      "  * Zeeman_Magnet_Unit::Zeeman_T -> 1 interlocks\n",
      "  * Laser_Coherence_Unit::Freq_THz -> 1 interlocks\n"
     ]
    }
   ],
   "source": [
    "# TITAN 0.1nm SINGULARITY ‚Äì CELL 6B\n",
    "# Add units, conversion formulas, readbacks, and interlocks\n",
    "\n",
    "import json\n",
    "\n",
    "print(\"SYSTEM ONLINE :: TITAN 0.1nm SINGULARITY CELL 6C\")\n",
    "\n",
    "IN_IO_PATH  = \"titan_0_1nm_control_IO_map.json\"\n",
    "OUT_IO_PATH = \"titan_0_1nm_control_IO_map_v2.json\"\n",
    "\n",
    "with open(IN_IO_PATH, \"r\") as f:\n",
    "    io_map = json.load(f)\n",
    "\n",
    "print(\"Loaded IO map version:\", io_map[\"meta\"][\"version\"])\n",
    "\n",
    "channels = io_map[\"channels\"]\n",
    "\n",
    "# Build a quick lookup for shield_state unique_id\n",
    "shield_channel_uid = None\n",
    "for ch in channels:\n",
    "    if ch[\"parameter_key\"] == \"shield_state\":\n",
    "        shield_channel_uid = ch[\"unique_id\"]\n",
    "        break\n",
    "\n",
    "# Helper: enrich a channel with units, conversion, readback, interlocks\n",
    "def enrich_channel(ch):\n",
    "    pk = ch[\"parameter_key\"]\n",
    "    iface = ch[\"interface_type\"]\n",
    "    sr_min, sr_max = ch[\"safe_range\"]\n",
    "\n",
    "    # Defaults\n",
    "    ch[\"units\"] = \"arb\"\n",
    "    ch[\"conversion_to_physical\"] = \"identity: physical = control_value\"\n",
    "    ch[\"readback_channel\"] = {\n",
    "        \"type\": \"NONE\",\n",
    "        \"channel_id\": None,\n",
    "        \"units\": None\n",
    "    }\n",
    "    ch[\"interlocks\"] = []\n",
    "\n",
    "    # Majorana gap ‚Äì virtual\n",
    "    if pk == \"Gap_meV\":\n",
    "        ch[\"units\"] = \"meV\"\n",
    "        ch[\"conversion_to_physical\"] = (\n",
    "            \"virtual: Gap_meV is inferred from Rashba_eV + Zeeman_T + device model, \"\n",
    "            \"not directly set via hardware\"\n",
    "        )\n",
    "        ch[\"readback_channel\"] = {\n",
    "            \"type\": \"ANALYSIS_DERIVED\",\n",
    "            \"channel_id\": \"ANALYSIS_PIPELINE_GAP\",\n",
    "            \"units\": \"meV\"\n",
    "        }\n",
    "\n",
    "    # Floquet drive frequency\n",
    "    elif pk == \"drive_freq_THz\":\n",
    "        ch[\"units\"] = \"THz\"\n",
    "        ch[\"conversion_to_physical\"] = (\n",
    "            \"f_THz = f_synth / 1e12, where f_synth is the RF synthesizer frequency in Hz \"\n",
    "            \"programmed via OLL_CH_01\"\n",
    "        )\n",
    "        ch[\"readback_channel\"] = {\n",
    "            \"type\": \"PLL_MONITOR\",\n",
    "            \"channel_id\": \"OLL_CH_01_MON\",\n",
    "            \"units\": \"Hz\"\n",
    "        }\n",
    "        if shield_channel_uid:\n",
    "            ch[\"interlocks\"].append({\n",
    "                \"condition\": f\"{shield_channel_uid} == 1\",\n",
    "                \"action\": \"ALLOW_OUTPUT\",\n",
    "                \"else_action\": \"FORCE_OUTPUT_OFF\",\n",
    "                \"description\": \"Enable Floquet drive only when thermal shielding is closed.\"\n",
    "            })\n",
    "\n",
    "    # Floquet amplitude\n",
    "    elif pk == \"drive_amplitude_rel\":\n",
    "        ch[\"units\"] = \"relative\"\n",
    "        ch[\"conversion_to_physical\"] = (\n",
    "            \"V_RMS = drive_amplitude_rel * V_ref, where V_ref is AWG full-scale voltage\"\n",
    "        )\n",
    "        ch[\"readback_channel\"] = {\n",
    "            \"type\": \"AWG_MONITOR\",\n",
    "            \"channel_id\": \"AWG_MOD_CH01_MON\",\n",
    "            \"units\": \"V_RMS\"\n",
    "        }\n",
    "        if shield_channel_uid:\n",
    "            ch[\"interlocks\"].append({\n",
    "                \"condition\": f\"{shield_channel_uid} == 1\",\n",
    "                \"action\": \"ALLOW_OUTPUT\",\n",
    "                \"else_action\": \"FORCE_OUTPUT_OFF\",\n",
    "                \"description\": \"Disable RF modulation if shield is open.\"\n",
    "            })\n",
    "\n",
    "    # Floquet subharmonic ratio\n",
    "    elif pk == \"subharmonic_ratio\":\n",
    "        ch[\"units\"] = \"dimensionless\"\n",
    "        ch[\"conversion_to_physical\"] = (\n",
    "            \"subharmonic_ratio = f_drive / f_response_peak, monitored by spectrum analyzer\"\n",
    "        )\n",
    "        ch[\"readback_channel\"] = {\n",
    "            \"type\": \"SPECTRUM_ANALYZER\",\n",
    "            \"channel_id\": \"SPEC_TC_PEAK\",\n",
    "            \"units\": \"ratio\"\n",
    "        }\n",
    "\n",
    "    # Rashba gate\n",
    "    elif pk == \"Rashba_eV\":\n",
    "        ch[\"units\"] = \"eV equivalent\"\n",
    "        ch[\"conversion_to_physical\"] = (\n",
    "            \"Rashba_eV = alpha * V_gate, where V_gate is DAC voltage and alpha is \"\n",
    "            \"device- and geometry-specific calibration (eV/V)\"\n",
    "        )\n",
    "        ch[\"readback_channel\"] = {\n",
    "            \"type\": \"DAC_VMON\",\n",
    "            \"channel_id\": \"DAC_SLOT3_CH04_MON\",\n",
    "            \"units\": \"V\"\n",
    "        }\n",
    "\n",
    "    # Zeeman field\n",
    "    elif pk == \"Zeeman_T\":\n",
    "        ch[\"units\"] = \"Tesla\"\n",
    "        ch[\"conversion_to_physical\"] = (\n",
    "            \"B_T = k_BI * I_coil, where I_coil is PSU_MAIN_COIL current in A and k_BI is \"\n",
    "            \"coil calibration factor (T/A)\"\n",
    "        )\n",
    "        ch[\"readback_channel\"] = {\n",
    "            \"type\": \"PSU_IMON\",\n",
    "            \"channel_id\": \"PSU_MAIN_COIL_IMON\",\n",
    "            \"units\": \"A\"\n",
    "        }\n",
    "        if shield_channel_uid:\n",
    "            ch[\"interlocks\"].append({\n",
    "                \"condition\": f\"{shield_channel_uid} == 1\",\n",
    "                \"action\": \"ALLOW_RAMP\",\n",
    "                \"else_action\": \"HOLD_FIELD_AT_0\",\n",
    "                \"description\": \"Do not ramp Zeeman field with shield open.\"\n",
    "            })\n",
    "\n",
    "    # Laser base frequency\n",
    "    elif pk == \"Freq_THz\":\n",
    "        ch[\"units\"] = \"THz\"\n",
    "        ch[\"conversion_to_physical\"] = (\n",
    "            \"Laser frequency in THz; control maps to cavity or comb offset via OLL_CH_01.\"\n",
    "        )\n",
    "        ch[\"readback_channel\"] = {\n",
    "            \"type\": \"FREQUENCY_COUNTER\",\n",
    "            \"channel_id\": \"LASER_FREQ_MON\",\n",
    "            \"units\": \"Hz\"\n",
    "        }\n",
    "        if shield_channel_uid:\n",
    "            ch[\"interlocks\"].append({\n",
    "                \"condition\": f\"{shield_channel_uid} == 1\",\n",
    "                \"action\": \"ALLOW_LOCK\",\n",
    "                \"else_action\": \"UNLOCK_AND_SHUTTER\",\n",
    "                \"description\": \"Require closed shield for laser lock and beam unshuttering.\"\n",
    "            })\n",
    "\n",
    "    # Fridge and shield\n",
    "    elif pk == \"fridge_setpoint_mK\":\n",
    "        ch[\"units\"] = \"mK\"\n",
    "        ch[\"conversion_to_physical\"] = (\n",
    "            \"Fridge temperature setpoint in mK; maps to cryostat controller setpoint.\"\n",
    "        )\n",
    "        ch[\"readback_channel\"] = {\n",
    "            \"type\": \"THERMOMETER\",\n",
    "            \"channel_id\": \"TEMP_STAGE_MIXER\",\n",
    "            \"units\": \"mK\"\n",
    "        }\n",
    "    elif pk == \"shield_state\":\n",
    "        ch[\"units\"] = \"logic\"\n",
    "        ch[\"conversion_to_physical\"] = \"0 = open, 1 = closed; controlled by mechanical/EM shield actuator.\"\n",
    "        ch[\"readback_channel\"] = {\n",
    "            \"type\": \"LIMIT_SWITCH\",\n",
    "            \"channel_id\": \"SHIELD_LIMIT_SW\",\n",
    "            \"units\": \"logic\"\n",
    "        }\n",
    "\n",
    "    # Yield simulation controls\n",
    "    elif pk in (\"jitter_std_freq_ppm\", \"fabrication_offset_sigma\"):\n",
    "        ch[\"units\"] = \"dimensionless\"\n",
    "        ch[\"conversion_to_physical\"] = (\n",
    "            \"Simulation-only parameter; affects Monte Carlo sampling distributions.\"\n",
    "        )\n",
    "        ch[\"readback_channel\"] = {\n",
    "            \"type\": \"SOFTWARE_STATE\",\n",
    "            \"channel_id\": \"SIM_CONF_STATE\",\n",
    "            \"units\": \"config\"\n",
    "        }\n",
    "\n",
    "    # Error correction\n",
    "    elif pk == \"code_distance\":\n",
    "        ch[\"units\"] = \"distance\"\n",
    "        ch[\"conversion_to_physical\"] = (\n",
    "            \"Code distance; maps to number of physical qubits per logical qubit in FPGA configuration.\"\n",
    "        )\n",
    "        ch[\"readback_channel\"] = {\n",
    "            \"type\": \"FPGA_STATUS\",\n",
    "            \"channel_id\": \"FPGA_CORE_REG_04_RD\",\n",
    "            \"units\": \"int\"\n",
    "        }\n",
    "    elif pk == \"syndrome_cycle_time_ns\":\n",
    "        ch[\"units\"] = \"ns\"\n",
    "        ch[\"conversion_to_physical\"] = (\n",
    "            \"Cycle time in ns for syndrome extraction; sets FPGA timing for gate sequences.\"\n",
    "        )\n",
    "        ch[\"readback_channel\"] = {\n",
    "            \"type\": \"FPGA_STATUS\",\n",
    "            \"channel_id\": \"FPGA_CORE_REG_04_RD\",\n",
    "            \"units\": \"ns\"\n",
    "        }\n",
    "\n",
    "    # Control fabric\n",
    "    elif pk == \"max_parallel_experiments\":\n",
    "        ch[\"units\"] = \"count\"\n",
    "        ch[\"conversion_to_physical\"] = \"Maximum number of experiments that may run concurrently in scheduler.\"\n",
    "        ch[\"readback_channel\"] = {\n",
    "            \"type\": \"SCHEDULER_STATUS\",\n",
    "            \"channel_id\": \"SCHED_MAX_PAR_RD\",\n",
    "            \"units\": \"count\"\n",
    "        }\n",
    "    elif pk == \"trial_id_stride\":\n",
    "        ch[\"units\"] = \"ID_step\"\n",
    "        ch[\"conversion_to_physical\"] = \"Stride in experiment IDs; used for encoding metadata.\"\n",
    "        ch[\"readback_channel\"] = {\n",
    "            \"type\": \"SCHEDULER_STATUS\",\n",
    "            \"channel_id\": \"SCHED_TRIAL_STRIDE_RD\",\n",
    "            \"units\": \"ID_step\"\n",
    "        }\n",
    "\n",
    "    # Calibration\n",
    "    elif pk == \"calibration_interval_hours\":\n",
    "        ch[\"units\"] = \"hours\"\n",
    "        ch[\"conversion_to_physical\"] = \"Interval in hours between automated calibration runs.\"\n",
    "        ch[\"readback_channel\"] = {\n",
    "            \"type\": \"SOFTWARE_STATE\",\n",
    "            \"channel_id\": \"CALIB_SCHED_STATE\",\n",
    "            \"units\": \"hours\"\n",
    "        }\n",
    "\n",
    "    return ch\n",
    "\n",
    "# Enrich all channels\n",
    "for ch in channels:\n",
    "    enrich_channel(ch)\n",
    "\n",
    "# Update meta and export\n",
    "io_map[\"meta\"][\"version\"] = \"titan-singularity-io-v2\"\n",
    "io_map[\"meta\"][\"notes\"] = (\n",
    "    \"Added units, conversion formulas, readback channel descriptors, \"\n",
    "    \"and basic interlocks (shield/laser/Zeeman/Floquet).\"\n",
    ")\n",
    "\n",
    "with open(OUT_IO_PATH, \"w\") as f:\n",
    "    json.dump(io_map, f, indent=2)\n",
    "\n",
    "print(\"EXPORT COMPLETE ::\", OUT_IO_PATH)\n",
    "print(f\" - Channels enriched: {len(channels)}\")\n",
    "print(\"Sample channels with interlocks:\")\n",
    "for ch in channels:\n",
    "    if ch[\"interlocks\"]:\n",
    "        print(f\"  * {ch['unique_id']} -> {len(ch['interlocks'])} interlocks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db66f4c3",
   "metadata": {
    "papermill": {
     "duration": 0.005855,
     "end_time": "2026-01-22T23:34:23.201078",
     "exception": false,
     "start_time": "2026-01-22T23:34:23.195223",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 9262827,
     "sourceId": 14502759,
     "sourceType": "datasetVersion"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 64.314229,
   "end_time": "2026-01-22T23:34:25.993132",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2026-01-22T23:33:21.678903",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "1577fcc05a6143ef83777748044d9566": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": "hidden",
       "width": null
      }
     },
     "2136fec42d804dc7bd3ba6a000ba6e40": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_eaaf9e70e78c44a987dcc2bd12df5b9f",
        "IPY_MODEL_538754dfff1942d3ae702e810ca48d4a",
        "IPY_MODEL_3061e99b937a480b81d3949d83c99a9d"
       ],
       "layout": "IPY_MODEL_1577fcc05a6143ef83777748044d9566",
       "tabbable": null,
       "tooltip": null
      }
     },
     "3061e99b937a480b81d3949d83c99a9d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_4c1e17e98c3049c398fef2d99b4614fb",
       "placeholder": "‚Äã",
       "style": "IPY_MODEL_9479f0c9a5254d0cae1c7c3d5e54ad28",
       "tabbable": null,
       "tooltip": null,
       "value": "‚Äá338/400‚Äá[00:01&lt;00:00,‚Äá503.56it/s]"
      }
     },
     "3e0537fff03744159a56c06717573dd0": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": "hidden",
       "width": null
      }
     },
     "4c1e17e98c3049c398fef2d99b4614fb": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4e06b1b9dd814bbba9c248c8b29d35ff": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "538754dfff1942d3ae702e810ca48d4a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_bab5d61a026b48eaab9f2f7cbb7cbc14",
       "max": 400.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_4e06b1b9dd814bbba9c248c8b29d35ff",
       "tabbable": null,
       "tooltip": null,
       "value": 400.0
      }
     },
     "6e22fb96e68d43fdaa555912a2ab2d68": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "786e17d9ce634fd296cf9b05b5ca5cce": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_b61335f63526405b93314e4ec5e3f0f7",
        "IPY_MODEL_df52383f99504005912cf0ea055e56f6",
        "IPY_MODEL_abf43ac388ac4d508cfd9f82cbd2da20"
       ],
       "layout": "IPY_MODEL_3e0537fff03744159a56c06717573dd0",
       "tabbable": null,
       "tooltip": null
      }
     },
     "7a774651f8c94951ab4e260fe92d6380": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "8ea13efb4efb4a31839e753ab0cd3106": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "9479f0c9a5254d0cae1c7c3d5e54ad28": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "abf43ac388ac4d508cfd9f82cbd2da20": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_e41c560ac65942538ef04782c2f697cd",
       "placeholder": "‚Äã",
       "style": "IPY_MODEL_c471b86f8bbf4fb1a8f887b6f70e47e2",
       "tabbable": null,
       "tooltip": null,
       "value": "‚Äá399/400‚Äá[00:00&lt;00:00,‚Äá669.88it/s]"
      }
     },
     "b31929eb72464bd6a861bb03160b5373": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "b61335f63526405b93314e4ec5e3f0f7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_ff9b300160a64583bac1fd7e62bf731d",
       "placeholder": "‚Äã",
       "style": "IPY_MODEL_7a774651f8c94951ab4e260fe92d6380",
       "tabbable": null,
       "tooltip": null,
       "value": "‚Äá‚Äá‚ÄáTraining‚ÄáGPU‚ÄáSurrogate:‚Äá100%"
      }
     },
     "bab5d61a026b48eaab9f2f7cbb7cbc14": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c471b86f8bbf4fb1a8f887b6f70e47e2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "df52383f99504005912cf0ea055e56f6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_eadad27c29434486b9cd15d1328bfe83",
       "max": 400.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_8ea13efb4efb4a31839e753ab0cd3106",
       "tabbable": null,
       "tooltip": null,
       "value": 400.0
      }
     },
     "e41c560ac65942538ef04782c2f697cd": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "eaaf9e70e78c44a987dcc2bd12df5b9f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_6e22fb96e68d43fdaa555912a2ab2d68",
       "placeholder": "‚Äã",
       "style": "IPY_MODEL_b31929eb72464bd6a861bb03160b5373",
       "tabbable": null,
       "tooltip": null,
       "value": "‚Äá‚Äá‚ÄáTraining‚ÄáSurrogate:‚Äá‚Äá84%"
      }
     },
     "eadad27c29434486b9cd15d1328bfe83": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ff9b300160a64583bac1fd7e62bf731d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
